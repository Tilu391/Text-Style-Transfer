{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-22T03:35:20.025918Z","iopub.status.busy":"2024-04-22T03:35:20.025633Z","iopub.status.idle":"2024-04-22T03:35:20.917068Z","shell.execute_reply":"2024-04-22T03:35:20.916149Z","shell.execute_reply.started":"2024-04-22T03:35:20.025895Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/Entertainment_Music/model_outputs/informal.nmt_copy\n","/kaggle/input/Entertainment_Music/model_outputs/formal.nmt_baseline\n","/kaggle/input/Entertainment_Music/model_outputs/formal.nmt_combined\n","/kaggle/input/Entertainment_Music/model_outputs/informal.nmt_combined\n","/kaggle/input/Entertainment_Music/model_outputs/informal.rule_based\n","/kaggle/input/Entertainment_Music/model_outputs/informal.pbmt\n","/kaggle/input/Entertainment_Music/model_outputs/formal.nmt_copy\n","/kaggle/input/Entertainment_Music/model_outputs/formal.pbmt\n","/kaggle/input/Entertainment_Music/model_outputs/informal.nmt_baseline\n","/kaggle/input/Entertainment_Music/model_outputs/formal.rule_based\n","/kaggle/input/Entertainment_Music/tune/formal\n","/kaggle/input/Entertainment_Music/tune/informal.ref2\n","/kaggle/input/Entertainment_Music/tune/formal.ref2\n","/kaggle/input/Entertainment_Music/tune/formal.ref3\n","/kaggle/input/Entertainment_Music/tune/formal.ref1\n","/kaggle/input/Entertainment_Music/tune/informal\n","/kaggle/input/Entertainment_Music/tune/formal.ref0\n","/kaggle/input/Entertainment_Music/tune/informal.ref3\n","/kaggle/input/Entertainment_Music/tune/informal.ref0\n","/kaggle/input/Entertainment_Music/tune/informal.ref1\n","/kaggle/input/Entertainment_Music/test/formal\n","/kaggle/input/Entertainment_Music/test/informal.ref2\n","/kaggle/input/Entertainment_Music/test/formal.ref2\n","/kaggle/input/Entertainment_Music/test/formal.ref3\n","/kaggle/input/Entertainment_Music/test/formal.ref1\n","/kaggle/input/Entertainment_Music/test/informal\n","/kaggle/input/Entertainment_Music/test/formal.ref0\n","/kaggle/input/Entertainment_Music/test/informal.ref3\n","/kaggle/input/Entertainment_Music/test/informal.ref0\n","/kaggle/input/Entertainment_Music/test/informal.ref1\n","/kaggle/input/Entertainment_Music/train/formal\n","/kaggle/input/Entertainment_Music/train/informal\n","/kaggle/input/Family_Relationships/model_outputs/informal.nmt_copy\n","/kaggle/input/Family_Relationships/model_outputs/formal.nmt_baseline\n","/kaggle/input/Family_Relationships/model_outputs/formal.nmt_combined\n","/kaggle/input/Family_Relationships/model_outputs/informal.nmt_combined\n","/kaggle/input/Family_Relationships/model_outputs/informal.rule_based\n","/kaggle/input/Family_Relationships/model_outputs/informal.pbmt\n","/kaggle/input/Family_Relationships/model_outputs/formal.nmt_copy\n","/kaggle/input/Family_Relationships/model_outputs/formal.pbmt\n","/kaggle/input/Family_Relationships/model_outputs/informal.nmt_baseline\n","/kaggle/input/Family_Relationships/model_outputs/formal.rule_based\n","/kaggle/input/Family_Relationships/tune/formal\n","/kaggle/input/Family_Relationships/tune/informal.ref2\n","/kaggle/input/Family_Relationships/tune/formal.ref2\n","/kaggle/input/Family_Relationships/tune/formal.ref3\n","/kaggle/input/Family_Relationships/tune/formal.ref1\n","/kaggle/input/Family_Relationships/tune/informal\n","/kaggle/input/Family_Relationships/tune/formal.ref0\n","/kaggle/input/Family_Relationships/tune/informal.ref3\n","/kaggle/input/Family_Relationships/tune/informal.ref0\n","/kaggle/input/Family_Relationships/tune/informal.ref1\n","/kaggle/input/Family_Relationships/test/formal\n","/kaggle/input/Family_Relationships/test/informal.ref2\n","/kaggle/input/Family_Relationships/test/formal.ref2\n","/kaggle/input/Family_Relationships/test/formal.ref3\n","/kaggle/input/Family_Relationships/test/formal.ref1\n","/kaggle/input/Family_Relationships/test/informal\n","/kaggle/input/Family_Relationships/test/formal.ref0\n","/kaggle/input/Family_Relationships/test/informal.ref3\n","/kaggle/input/Family_Relationships/test/informal.ref0\n","/kaggle/input/Family_Relationships/test/informal.ref1\n","/kaggle/input/Family_Relationships/train/formal\n","/kaggle/input/Family_Relationships/train/informal\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:35:20.919817Z","iopub.status.busy":"2024-04-22T03:35:20.919042Z","iopub.status.idle":"2024-04-22T03:35:59.394651Z","shell.execute_reply":"2024-04-22T03:35:59.393703Z","shell.execute_reply.started":"2024-04-22T03:35:20.919781Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: transformers 4.39.3\n","Uninstalling transformers-4.39.3:\n","  Successfully uninstalled transformers-4.39.3\n","Collecting transformers\n","  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.20,>=0.19 (from transformers)\n","  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.2\n","    Uninstalling tokenizers-0.15.2:\n","      Successfully uninstalled tokenizers-0.15.2\n","Successfully installed tokenizers-0.19.1 transformers-4.40.0\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\n","Collecting accelerate\n","  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n","\u001b[?25hInstalling collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.28.0\n","    Uninstalling accelerate-0.28.0:\n","      Successfully uninstalled accelerate-0.28.0\n","Successfully installed accelerate-0.29.3\n"]}],"source":["!pip uninstall -y transformers\n","!pip install transformers\n","!pip install accelerate -U"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:35:59.396967Z","iopub.status.busy":"2024-04-22T03:35:59.396215Z","iopub.status.idle":"2024-04-22T03:36:21.920556Z","shell.execute_reply":"2024-04-22T03:36:21.919810Z","shell.execute_reply.started":"2024-04-22T03:35:59.396926Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-22 03:36:06.791545: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-22 03:36:06.791644: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-22 03:36:06.891027: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23baa88c2d8a4d80bd4112d91689414d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c82b7cc1263c477e9c63c4f35e424ac6","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82dbb4785111415981c2cb73b4015446","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","model_checkpoint = \"t5-base\"\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:36:21.922881Z","iopub.status.busy":"2024-04-22T03:36:21.922340Z","iopub.status.idle":"2024-04-22T03:36:22.033609Z","shell.execute_reply":"2024-04-22T03:36:22.032833Z","shell.execute_reply.started":"2024-04-22T03:36:21.922854Z"},"trusted":true},"outputs":[],"source":["batch_size = 16\n","model_name = model_checkpoint.split(\"/\")[-1]\n","args = Seq2SeqTrainingArguments(\n","    f\"{model_name}-finetuned\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=5,\n","    predict_with_generate=True,\n","     fp16=True,\n","    push_to_hub=True,\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:36:22.034872Z","iopub.status.busy":"2024-04-22T03:36:22.034603Z","iopub.status.idle":"2024-04-22T03:36:22.661467Z","shell.execute_reply":"2024-04-22T03:36:22.660034Z","shell.execute_reply.started":"2024-04-22T03:36:22.034848Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /usr/share/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:36:22.664541Z","iopub.status.busy":"2024-04-22T03:36:22.663429Z","iopub.status.idle":"2024-04-22T03:42:20.455981Z","shell.execute_reply":"2024-04-22T03:42:20.455020Z","shell.execute_reply.started":"2024-04-22T03:36:22.664484Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.795009280263972\n","Confusion Matrix:\n","[[1541  560]\n"," [ 434 2314]]\n"]}],"source":["import os\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from nltk.stem import SnowballStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk import pos_tag\n","from nltk.corpus import stopwords\n","\n","# Initialize Snowball stemmer\n","stemmer = SnowballStemmer(\"english\")\n","\n","# Initialize stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","# Function to apply stemming to a sentence using Snowball stemmer\n","def apply_stemming(sentence):\n","    tokens = word_tokenize(sentence)\n","    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n","    return ' '.join(stemmed_tokens)\n","\n","# Function to replace terms with POS tags based on weights from the model\n","def replace_with_pos_tags(sentence, weights, is_formal):\n","    tokens = word_tokenize(sentence)\n","    stemmed_tokens = [stemmer.stem(token) for token in tokens]  # Stem tokens\n","    pos_tags = pos_tag(tokens)  # Use original tokens for POS tagging\n","    replaced_sentence = []\n","\n","    # Calculate N as described\n","    N = len(stemmed_tokens) // 4\n","\n","    # Filter out stop words and stem them\n","    tokens_without_stopwords = [stemmer.stem(token) for token in tokens if token.lower() not in stop_words]\n","\n","    # Sort stemmed tokens by weight\n","    sorted_tokens = sorted(tokens_without_stopwords, key=lambda x: abs(weights.get(x, 0)), reverse=True)\n","\n","    # Extract N tokens with highest absolute weights\n","    top_N_tokens = sorted_tokens[:N]\n","\n","    for token, tag in pos_tags:\n","        stemmed_token = stemmer.stem(token)\n","        if stemmed_token in top_N_tokens:\n","            weight = abs(weights.get(stemmed_token, 0))\n","            if (is_formal and weight >= 0.01) or (not is_formal and weight >= 0.02):\n","                replaced_sentence.append(tag)\n","            else:\n","                replaced_sentence.append(token)\n","        else:\n","            replaced_sentence.append(token)\n","\n","    return ' '.join(replaced_sentence)\n","\n","def read_data(file_path):\n","    with open(file_path, \"r\", encoding=\"latin-1\") as file:\n","        sentences = file.readlines()\n","    return [apply_stemming(sentence.strip()) for sentence in sentences]\n","\n","# Paths to data files\n","train_formal_path_1 = \"/kaggle/input/Entertainment_Music/train/formal\"\n","train_informal_path_1 = \"/kaggle/input/Entertainment_Music/train/informal\"\n","test_formal_path_1 = \"/kaggle/input/Entertainment_Music/test/formal\"\n","test_informal_path_1 = \"/kaggle/input/Entertainment_Music/test/informal\"\n","\n","train_formal_path_2 = \"/kaggle/input/Family_Relationships/train/formal\"\n","train_informal_path_2 = \"/kaggle/input/Family_Relationships/train/informal\"\n","test_formal_path_2 = \"/kaggle/input/Family_Relationships/test/formal\"\n","test_informal_path_2 = \"/kaggle/input/Family_Relationships/test/informal\"\n","\n","X_train = (read_data(train_formal_path_1) + read_data(train_formal_path_2) +\n","           read_data(train_informal_path_1) + read_data(train_informal_path_2))\n","Y_train = [0] * (len(read_data(train_formal_path_1)) + len(read_data(train_formal_path_2))) + \\\n","          [1] * (len(read_data(train_informal_path_1)) + len(read_data(train_informal_path_2)))  # Labels for training data\n","\n","X_test = read_data(test_formal_path_1) + read_data(test_formal_path_2) + \\\n","         read_data(test_informal_path_1) + read_data(test_informal_path_2)\n","Y_test = [0] * (len(read_data(test_formal_path_1)) + len(read_data(test_formal_path_2))) + \\\n","         [1] * (len(read_data(test_informal_path_1)) + len(read_data(test_informal_path_2)))  # Labels for test data\n","\n","\n","# Initialize TfidfVectorizer with n-grams\n","vectorizer = TfidfVectorizer(max_features=200000, ngram_range=(1, 3), min_df=1, max_df=0.85)\n","\n","\n","# Initialize StandardScaler for scaling the data\n","scaler = StandardScaler(with_mean=False)\n","\n","# Create a Pipeline for preprocessing and model training\n","pipeline = Pipeline([\n","    ('vectorizer', vectorizer),\n","    ('classifier', LogisticRegression( max_iter=5000))\n","])\n","\n","# Fit the pipeline on the training data\n","pipeline.fit(X_train, Y_train)\n","\n","# Extract feature names from the vectorizer\n","# feature_names = vectorizer.get_feature_names()\n","feature_names = vectorizer.get_feature_names_out()\n","\n","\n","# Extract coefficients (weights) from the logistic regression model\n","weights = dict(zip(feature_names, pipeline.named_steps['classifier'].coef_[0]))\n","\n","# Set threshold for replacing terms with POS tags\n","# threshold = 0.2\n","\n","# Replace terms with POS tags in the training data itself\n","X_train_transformed = [replace_with_pos_tags(X_train[i], weights, not(Y_train[i])) for i  in range(len(X_train))]\n","\n","# Print out the original and transformed sentences\n","# for original_sentence, transformed_sentence in zip(X_train, X_train_transformed):\n","#     print(\"Original Sentence:\", original_sentence)\n","#     print(\"Transformed Sentence:\", transformed_sentence)\n","#     print()  # Add a newline for clarity\n","\n","# Make predictions on the test data\n","predicted_probabilities = pipeline.predict_proba(X_test)\n","\n","# Define a new threshold\n","new_threshold = 0.42  # Example threshold, you can adjust it according to your needs\n","\n","# Modify predictions based on the new threshold\n","predicted_labels = (predicted_probabilities[:, 1] >= new_threshold).astype(int)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(Y_test, predicted_labels)\n","print(\"Accuracy:\", accuracy)\n","\n","# Compute confusion matrix\n","cm = confusion_matrix(Y_test, predicted_labels)\n","print(\"Confusion Matrix:\")\n","print(cm)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:43:35.206029Z","iopub.status.busy":"2024-04-22T03:43:35.205351Z","iopub.status.idle":"2024-04-22T03:43:35.215145Z","shell.execute_reply":"2024-04-22T03:43:35.214186Z","shell.execute_reply.started":"2024-04-22T03:43:35.205992Z"},"trusted":true},"outputs":[],"source":["def replace_with_pos_tags(sentence, weights, is_formal):\n","    tokens = word_tokenize(sentence)\n","    stemmed_tokens = [stemmer.stem(token) for token in tokens]  # Stem tokens\n","    pos_tags = pos_tag(tokens)  # Use original tokens for POS tagging\n","    replaced_sentence = []\n","\n","    # Calculate N as described\n","    N = len(stemmed_tokens) // 4\n","\n","    # Filter out stop words and stem them\n","    tokens_without_stopwords = [stemmer.stem(token) for token in tokens if token.lower() not in stop_words]\n","\n","    # Sort stemmed tokens by weight\n","    sorted_tokens = sorted(tokens_without_stopwords, key=lambda x: abs(weights.get(x, 0)), reverse=True)\n","\n","    # Extract N tokens with highest absolute weights\n","    top_N_tokens = sorted_tokens[:N]\n","\n","    for token, tag in pos_tags:\n","        stemmed_token = stemmer.stem(token)\n","        if stemmed_token in top_N_tokens:\n","            weight = abs(weights.get(stemmed_token, 0))\n","            if (is_formal and weight >= 0.01) or (not is_formal and weight >= 0.02):\n","                replaced_sentence.append(tag)\n","            else:\n","                replaced_sentence.append(token)\n","        else:\n","            replaced_sentence.append(token)\n","\n","    return ' '.join(replaced_sentence)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:53:53.670966Z","iopub.status.busy":"2024-04-22T03:53:53.670081Z","iopub.status.idle":"2024-04-22T03:53:53.675791Z","shell.execute_reply":"2024-04-22T03:53:53.674853Z","shell.execute_reply.started":"2024-04-22T03:53:53.670933Z"},"trusted":true},"outputs":[],"source":["def read_data(file_path):\n","    with open(file_path, \"r\", encoding=\"latin-1\") as file:\n","        sentences = file.readlines()\n","    return [sentence.strip() for sentence in sentences]"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:53:55.597857Z","iopub.status.busy":"2024-04-22T03:53:55.597471Z","iopub.status.idle":"2024-04-22T03:53:55.749209Z","shell.execute_reply":"2024-04-22T03:53:55.748419Z","shell.execute_reply.started":"2024-04-22T03:53:55.597828Z"},"trusted":true},"outputs":[],"source":["X_train = (read_data(train_formal_path_1) + read_data(train_formal_path_2) +\n","           read_data(train_informal_path_1) + read_data(train_informal_path_2))\n","Y_train = [0] * (len(read_data(train_formal_path_1)) + len(read_data(train_formal_path_2))) + \\\n","          [1] * (len(read_data(train_informal_path_1)) + len(read_data(train_informal_path_2)))  # Labels for training data\n","\n","X_test = read_data(test_formal_path_1) + read_data(test_formal_path_2) + \\\n","         read_data(test_informal_path_1) + read_data(test_informal_path_2)\n","Y_test = [0] * (len(read_data(test_formal_path_1)) + len(read_data(test_formal_path_2))) + \\\n","         [1] * (len(read_data(test_informal_path_1)) + len(read_data(test_informal_path_2)))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:54:50.009989Z","iopub.status.busy":"2024-04-22T03:54:50.009635Z","iopub.status.idle":"2024-04-22T03:59:31.801064Z","shell.execute_reply":"2024-04-22T03:59:31.800032Z","shell.execute_reply.started":"2024-04-22T03:54:50.009960Z"},"trusted":true},"outputs":[],"source":["X_train_transformed = [replace_with_pos_tags(X_train[i], weights, not(Y_train[i])) for i  in range(len(X_train))]\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:43:37.451800Z","iopub.status.busy":"2024-04-22T03:43:37.450910Z","iopub.status.idle":"2024-04-22T03:43:37.458898Z","shell.execute_reply":"2024-04-22T03:43:37.457936Z","shell.execute_reply.started":"2024-04-22T03:43:37.451764Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"There 's nothing he VBZ to VB .\""]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["new=replace_with_pos_tags(\"There's nothing he needs to change.\", weights, True)\n","\n","new"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:49:04.681549Z","iopub.status.busy":"2024-04-22T04:49:04.680860Z","iopub.status.idle":"2024-04-22T04:49:06.019655Z","shell.execute_reply":"2024-04-22T04:49:06.018567Z","shell.execute_reply.started":"2024-04-22T04:49:04.681510Z"},"trusted":true},"outputs":[],"source":["X_test=[apply_stemming(sentence) for sentence in X_test]"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:49:25.722101Z","iopub.status.busy":"2024-04-22T04:49:25.721232Z","iopub.status.idle":"2024-04-22T04:49:25.727581Z","shell.execute_reply":"2024-04-22T04:49:25.726557Z","shell.execute_reply.started":"2024-04-22T04:49:25.722065Z"},"trusted":true},"outputs":[],"source":["# X_test"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:49:29.125808Z","iopub.status.busy":"2024-04-22T04:49:29.125098Z","iopub.status.idle":"2024-04-22T04:49:29.268377Z","shell.execute_reply":"2024-04-22T04:49:29.266457Z","shell.execute_reply.started":"2024-04-22T04:49:29.125762Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7925345432047844\n","Confusion Matrix:\n","[[1631  470]\n"," [ 536 2212]]\n"]}],"source":["predicted_probabilities = pipeline.predict_proba(X_test)\n","\n","# Define a new threshold\n","new_threshold = 0.45  # Example threshold, you can adjust it according to your needs\n","\n","# Modify predictions based on the new threshold\n","predicted_labels = (predicted_probabilities[:, 1] >= new_threshold).astype(int)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(Y_test, predicted_labels)\n","print(\"Accuracy:\", accuracy)\n","\n","# Compute confusion matrix\n","cm = confusion_matrix(Y_test, predicted_labels)\n","print(\"Confusion Matrix:\")\n","print(cm)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:02:12.354267Z","iopub.status.busy":"2024-04-22T04:02:12.353384Z","iopub.status.idle":"2024-04-22T04:02:12.372191Z","shell.execute_reply":"2024-04-22T04:02:12.371294Z","shell.execute_reply.started":"2024-04-22T04:02:12.354230Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n","                 TfidfVectorizer(max_df=0.85, max_features=200000,\n","                                 ngram_range=(1, 3))),\n","                (&#x27;classifier&#x27;, LogisticRegression(max_iter=5000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n","                 TfidfVectorizer(max_df=0.85, max_features=200000,\n","                                 ngram_range=(1, 3))),\n","                (&#x27;classifier&#x27;, LogisticRegression(max_iter=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.85, max_features=200000, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5000)</pre></div></div></div></div></div></div></div>"],"text/plain":["Pipeline(steps=[('vectorizer',\n","                 TfidfVectorizer(max_df=0.85, max_features=200000,\n","                                 ngram_range=(1, 3))),\n","                ('classifier', LogisticRegression(max_iter=5000))])"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["pipeline\n"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:47.866221Z","iopub.status.busy":"2024-04-22T04:00:47.865599Z","iopub.status.idle":"2024-04-22T04:00:47.872995Z","shell.execute_reply":"2024-04-22T04:00:47.871901Z","shell.execute_reply.started":"2024-04-22T04:00:47.866180Z"},"trusted":true},"outputs":[{"data":{"text/plain":["4.204547427074"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["weights[\"crap\"]"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:54:16.232486Z","iopub.status.busy":"2024-04-22T03:54:16.232125Z","iopub.status.idle":"2024-04-22T03:54:22.823666Z","shell.execute_reply":"2024-04-22T03:54:22.822830Z","shell.execute_reply.started":"2024-04-22T03:54:16.232457Z"},"trusted":true},"outputs":[],"source":["X_test_transformed = [replace_with_pos_tags(X_test[i], weights, not(Y_test[i])) for i  in range(len(X_test))]"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:42.063884Z","iopub.status.busy":"2024-04-22T04:00:42.063043Z","iopub.status.idle":"2024-04-22T04:00:42.067615Z","shell.execute_reply":"2024-04-22T04:00:42.066663Z","shell.execute_reply.started":"2024-04-22T04:00:42.063847Z"},"trusted":true},"outputs":[],"source":["# X_test_transformed"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:59:39.084194Z","iopub.status.busy":"2024-04-22T03:59:39.083278Z","iopub.status.idle":"2024-04-22T03:59:52.096288Z","shell.execute_reply":"2024-04-22T03:59:52.095221Z","shell.execute_reply.started":"2024-04-22T03:59:39.084156Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Installing collected packages: responses, evaluate\n","Successfully installed evaluate-0.4.1 responses-0.18.0\n"]}],"source":["!pip install evaluate\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T03:59:52.099603Z","iopub.status.busy":"2024-04-22T03:59:52.098842Z","iopub.status.idle":"2024-04-22T04:00:06.771420Z","shell.execute_reply":"2024-04-22T04:00:06.770393Z","shell.execute_reply.started":"2024-04-22T03:59:52.099562Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a078449309afb09dadb855a745f6a9a4604219d9e1ac479840a87cce9d1a69d3\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}],"source":["from evaluate import load\n","!pip install rouge_score"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:06.773381Z","iopub.status.busy":"2024-04-22T04:00:06.772845Z","iopub.status.idle":"2024-04-22T04:00:07.347076Z","shell.execute_reply":"2024-04-22T04:00:07.346382Z","shell.execute_reply.started":"2024-04-22T04:00:06.773351Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d02afc68070b4086923b2da71c51c71d","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["metric1 = load(\"rouge\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:07.350577Z","iopub.status.busy":"2024-04-22T04:00:07.349918Z","iopub.status.idle":"2024-04-22T04:00:08.378119Z","shell.execute_reply":"2024-04-22T04:00:08.377193Z","shell.execute_reply.started":"2024-04-22T04:00:07.350548Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a3c8dc94dea455f98b6a143b516790d","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82ef8efb58064006879bfd083284d02a","version_major":2,"version_minor":0},"text/plain":["Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0bd5cac92a04e6ab8471c9ebb31b503","version_major":2,"version_minor":0},"text/plain":["Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["metric2 = load(\"bleu\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:08.379810Z","iopub.status.busy":"2024-04-22T04:00:08.379390Z","iopub.status.idle":"2024-04-22T04:00:09.811942Z","shell.execute_reply":"2024-04-22T04:00:09.811155Z","shell.execute_reply.started":"2024-04-22T04:00:08.379776Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b702436b4f074e98a3318cededaadfaa","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf6bfe7bb46e41bf8ea4069c5acd9115","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:09.813676Z","iopub.status.busy":"2024-04-22T04:00:09.813223Z","iopub.status.idle":"2024-04-22T04:00:09.894613Z","shell.execute_reply":"2024-04-22T04:00:09.893554Z","shell.execute_reply.started":"2024-04-22T04:00:09.813641Z"},"trusted":true},"outputs":[],"source":["def read_data(file_path):\n","    with open(file_path, \"r\", encoding=\"latin-1\") as file:\n","        sentences = file.readlines()\n","    return [sentence.strip() for sentence in sentences]\n","\n","\n","# Paths to data files\n","train_formal_path_1 = \"/kaggle/input/Entertainment_Music/train/formal\"\n","train_informal_path_1 = \"/kaggle/input/Entertainment_Music/train/informal\"\n","test_formal_path_1 = \"/kaggle/input/Entertainment_Music/test/formal\"\n","test_informal_path_1 = \"/kaggle/input/Entertainment_Music/test/informal\"\n","\n","train_formal_path_2 = \"/kaggle/input/Family_Relationships/train/formal\"\n","train_informal_path_2 = \"/kaggle/input/Family_Relationships/train/informal\"\n","test_formal_path_2 = \"/kaggle/input/Family_Relationships/test/formal\"\n","test_informal_path_2 = \"/kaggle/input/Family_Relationships/test/informal\"\n","\n","X_train_formal = (read_data(train_formal_path_1) + read_data(train_formal_path_2) )\n","X_train_informal = read_data(train_informal_path_1) + read_data(train_informal_path_2)\n","\n","\n","X_test_formal = read_data(test_formal_path_1) + read_data(test_formal_path_2)\n","X_test_informal = read_data(test_informal_path_1) + read_data(test_informal_path_2)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:09.896141Z","iopub.status.busy":"2024-04-22T04:00:09.895859Z","iopub.status.idle":"2024-04-22T04:00:09.905477Z","shell.execute_reply":"2024-04-22T04:00:09.904417Z","shell.execute_reply.started":"2024-04-22T04:00:09.896117Z"},"trusted":true},"outputs":[],"source":["X_train_formal_transformed=X_train_transformed[:len(X_train)//2]"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:09.907136Z","iopub.status.busy":"2024-04-22T04:00:09.906797Z","iopub.status.idle":"2024-04-22T04:00:09.913042Z","shell.execute_reply":"2024-04-22T04:00:09.912164Z","shell.execute_reply.started":"2024-04-22T04:00:09.907095Z"},"trusted":true},"outputs":[],"source":["X_test_formal_transformed=X_test_transformed[0:len(X_test_formal)]"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:09.914618Z","iopub.status.busy":"2024-04-22T04:00:09.914306Z","iopub.status.idle":"2024-04-22T04:00:09.940717Z","shell.execute_reply":"2024-04-22T04:00:09.939507Z","shell.execute_reply.started":"2024-04-22T04:00:09.914593Z"},"trusted":true},"outputs":[],"source":["train_formal_df = pd.DataFrame({ 'POS': X_train_formal_transformed, 'formal': X_train_formal,})"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:09.944224Z","iopub.status.busy":"2024-04-22T04:00:09.943907Z","iopub.status.idle":"2024-04-22T04:00:09.954045Z","shell.execute_reply":"2024-04-22T04:00:09.953151Z","shell.execute_reply.started":"2024-04-22T04:00:09.944199Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2    I watch it everyday, my favorite charachter is...\n","Name: formal, dtype: object"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["train_formal_df[\"formal\"][2:3]"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:00:09.955625Z","iopub.status.busy":"2024-04-22T04:00:09.955272Z","iopub.status.idle":"2024-04-22T04:00:09.962872Z","shell.execute_reply":"2024-04-22T04:00:09.961864Z","shell.execute_reply.started":"2024-04-22T04:00:09.955595Z"},"trusted":true},"outputs":[],"source":["test_formal_df = pd.DataFrame({ 'POS': X_test_formal_transformed, 'formal': X_test_formal,})"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:54:26.878260Z","iopub.status.busy":"2024-04-22T04:54:26.877895Z","iopub.status.idle":"2024-04-22T04:54:26.892631Z","shell.execute_reply":"2024-04-22T04:54:26.891391Z","shell.execute_reply.started":"2024-04-22T04:54:26.878230Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>POS</th>\n","      <th>formal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I like NNP and Blue music .</td>\n","      <td>I like Rhythm and Blue music.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>There 's nothing he VBZ to VB .</td>\n","      <td>There's nothing he needs to change.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>It does not VB .</td>\n","      <td>It does not exist.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mine is book by Steve Martin called POS NN of ...</td>\n","      <td>Mine is book by Steve Martin called 'The Pleas...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What VBZ a mosquitoo from a NN ?</td>\n","      <td>What differentiates a mosquitoo from a blonde?</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2096</th>\n","      <td>The world MD be happier if NNS knew what NNS w...</td>\n","      <td>The world would be happier if men knew what wo...</td>\n","    </tr>\n","    <tr>\n","      <th>2097</th>\n","      <td>You want to have oral NN with another NN ?</td>\n","      <td>You want to have oral sex with another man?</td>\n","    </tr>\n","    <tr>\n","      <th>2098</th>\n","      <td>I VBP you not marry .</td>\n","      <td>I prefer you not marry.</td>\n","    </tr>\n","    <tr>\n","      <th>2099</th>\n","      <td>Yes I am a NN , RB I do not RB have to pay .</td>\n","      <td>Yes I am a male, therefore I do not really hav...</td>\n","    </tr>\n","    <tr>\n","      <th>2100</th>\n","      <td>If he VBZ to VB my NNS , he only has to ask .</td>\n","      <td>If he wants to wear my pants, he only has to ask.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2101 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    POS  \\\n","0                           I like NNP and Blue music .   \n","1                       There 's nothing he VBZ to VB .   \n","2                                      It does not VB .   \n","3     Mine is book by Steve Martin called POS NN of ...   \n","4                      What VBZ a mosquitoo from a NN ?   \n","...                                                 ...   \n","2096  The world MD be happier if NNS knew what NNS w...   \n","2097         You want to have oral NN with another NN ?   \n","2098                              I VBP you not marry .   \n","2099       Yes I am a NN , RB I do not RB have to pay .   \n","2100      If he VBZ to VB my NNS , he only has to ask .   \n","\n","                                                 formal  \n","0                         I like Rhythm and Blue music.  \n","1                   There's nothing he needs to change.  \n","2                                    It does not exist.  \n","3     Mine is book by Steve Martin called 'The Pleas...  \n","4        What differentiates a mosquitoo from a blonde?  \n","...                                                 ...  \n","2096  The world would be happier if men knew what wo...  \n","2097        You want to have oral sex with another man?  \n","2098                            I prefer you not marry.  \n","2099  Yes I am a male, therefore I do not really hav...  \n","2100  If he wants to wear my pants, he only has to ask.  \n","\n","[2101 rows x 2 columns]"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["test_formal_df"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:54:02.219954Z","iopub.status.busy":"2024-04-22T04:54:02.219120Z","iopub.status.idle":"2024-04-22T04:54:02.233879Z","shell.execute_reply":"2024-04-22T04:54:02.232762Z","shell.execute_reply.started":"2024-04-22T04:54:02.219920Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>POS</th>\n","      <th>formal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The In-Laws NN is n't a JJ NN , but it 's NN .</td>\n","      <td>The In-Laws movie isn't a holiday movie, but i...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I do n't VB that page gave me NNS .</td>\n","      <td>I don't think that page gave me viruses.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I watch it JJ , my JJ charachter is Inuasha .</td>\n","      <td>I watch it everyday, my favorite charachter is...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Funbrain.com and runescape.com are JJ for fami...</td>\n","      <td>Funbrain.com and runescape.com are great for f...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>He was on the Late Night NN with Conan O'Brien...</td>\n","      <td>He was on the Late Night show with Conan O'Bri...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>104557</th>\n","      <td>Of NN , it depends on what type of NN you are ...</td>\n","      <td>Of course, it depends on what type of relation...</td>\n","    </tr>\n","    <tr>\n","      <th>104558</th>\n","      <td>IN a sign that say `` NNP ! ''</td>\n","      <td>Wear a sign that say \"Hi!\"</td>\n","    </tr>\n","    <tr>\n","      <th>104559</th>\n","      <td>I do not IN when NNS play games with me .</td>\n","      <td>I do not like when guys play games with me.</td>\n","    </tr>\n","    <tr>\n","      <th>104560</th>\n","      <td>How JJ are you ?</td>\n","      <td>How old are you?</td>\n","    </tr>\n","    <tr>\n","      <th>104561</th>\n","      <td>If you watch her , you MD be JJ to VB what she...</td>\n","      <td>If you watch her, you might be able to learn w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>104562 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                      POS  \\\n","0          The In-Laws NN is n't a JJ NN , but it 's NN .   \n","1                     I do n't VB that page gave me NNS .   \n","2           I watch it JJ , my JJ charachter is Inuasha .   \n","3       Funbrain.com and runescape.com are JJ for fami...   \n","4       He was on the Late Night NN with Conan O'Brien...   \n","...                                                   ...   \n","104557  Of NN , it depends on what type of NN you are ...   \n","104558                     IN a sign that say `` NNP ! ''   \n","104559          I do not IN when NNS play games with me .   \n","104560                                   How JJ are you ?   \n","104561  If you watch her , you MD be JJ to VB what she...   \n","\n","                                                   formal  \n","0       The In-Laws movie isn't a holiday movie, but i...  \n","1                I don't think that page gave me viruses.  \n","2       I watch it everyday, my favorite charachter is...  \n","3       Funbrain.com and runescape.com are great for f...  \n","4       He was on the Late Night show with Conan O'Bri...  \n","...                                                   ...  \n","104557  Of course, it depends on what type of relation...  \n","104558                         Wear a sign that say \"Hi!\"  \n","104559        I do not like when guys play games with me.  \n","104560                                   How old are you?  \n","104561  If you watch her, you might be able to learn w...  \n","\n","[104562 rows x 2 columns]"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["train_formal_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_formal_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"hello\")"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:03:08.156706Z","iopub.status.busy":"2024-04-22T04:03:08.155956Z","iopub.status.idle":"2024-04-22T04:03:32.828819Z","shell.execute_reply":"2024-04-22T04:03:32.827963Z","shell.execute_reply.started":"2024-04-22T04:03:08.156672Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["import pandas as pd\n","\n","# Assuming you already have X_train_formal_transformed and X_train_formal defined\n","train_formal_df = pd.DataFrame({'POS': X_train_formal_transformed, 'formal': X_train_formal})\n","\n","def preprocess_function(row):\n","    inputs = row[\"POS\"] + \"</s>\"\n","    model_inputs = tokenizer(inputs, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    labels = tokenizer(text_target=row[\"formal\"], truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_dataset_formal_train = train_formal_df.apply(preprocess_function, axis=1)\n","tokenized_dataset_formal_test = test_formal_df.apply(preprocess_function, axis=1)\n"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:03:32.830541Z","iopub.status.busy":"2024-04-22T04:03:32.830242Z","iopub.status.idle":"2024-04-22T04:03:32.834574Z","shell.execute_reply":"2024-04-22T04:03:32.833720Z","shell.execute_reply.started":"2024-04-22T04:03:32.830515Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM\n"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:03:32.836562Z","iopub.status.busy":"2024-04-22T04:03:32.835863Z","iopub.status.idle":"2024-04-22T04:03:32.855639Z","shell.execute_reply":"2024-04-22T04:03:32.854554Z","shell.execute_reply.started":"2024-04-22T04:03:32.836527Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","train_data, val_data = train_test_split(tokenized_dataset_formal_train, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:04:30.114258Z","iopub.status.busy":"2024-04-22T04:04:30.113873Z","iopub.status.idle":"2024-04-22T04:04:30.118691Z","shell.execute_reply":"2024-04-22T04:04:30.117568Z","shell.execute_reply.started":"2024-04-22T04:04:30.114226Z"},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T05:30:42.729540Z","iopub.status.busy":"2024-04-22T05:30:42.728886Z","iopub.status.idle":"2024-04-22T05:30:42.742197Z","shell.execute_reply":"2024-04-22T05:30:42.741048Z","shell.execute_reply.started":"2024-04-22T05:30:42.729492Z"},"trusted":true},"outputs":[],"source":["import nltk\n","import numpy as np\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    preds=[apply_stemming(sentence) for sentence in  decoded_preds]\n","\n","    # Use logistic regression model to predict formality of decoded sentences\n","    predicted_formality = pipeline.predict(preds)\n","\n","    # Calculate accuracy based on logistic regression model's predictions\n","    total_samples = len(decoded_preds)\n","    correct_predictions = sum(predicted_formality == 0)  # Count how many were predicted as formal (0)\n","    accuracy_log_reg = correct_predictions / total_samples\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","\n","    # Note that other metrics may not have a `use_aggregator` parameter\n","    # and thus will return a list, computing a metric for each sentence.\n","    result = metric1.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n","    # Extract a few results\n","    result = {key: value * 100 for key, value in result.items()}\n","\n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    # Add accuracy based on logistic regression model's predictions\n","    result[\"accuracy_log_reg\"] = accuracy_log_reg\n","    \n","    print(result)\n","\n","    return {k: round(v, 4) for k, v in result.items()}\n"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:04:51.618866Z","iopub.status.busy":"2024-04-22T04:04:51.618462Z","iopub.status.idle":"2024-04-22T04:04:51.966003Z","shell.execute_reply":"2024-04-22T04:04:51.965214Z","shell.execute_reply.started":"2024-04-22T04:04:51.618837Z"},"trusted":true},"outputs":[],"source":["train_dataset = train_data.to_frame().to_dict(orient='records')\n","val_dataset = val_data.to_frame().to_dict(orient='records')"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:04:52.206325Z","iopub.status.busy":"2024-04-22T04:04:52.205961Z","iopub.status.idle":"2024-04-22T04:04:52.252450Z","shell.execute_reply":"2024-04-22T04:04:52.251576Z","shell.execute_reply.started":"2024-04-22T04:04:52.206296Z"},"trusted":true},"outputs":[],"source":["train_dataset1 = [v for d in train_dataset for k, v in d.items()]\n","val_dataset1=[v for d in val_dataset for k, v in d.items()]"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T02:10:50.474428Z","iopub.status.busy":"2024-04-21T02:10:50.474117Z","iopub.status.idle":"2024-04-21T02:10:50.481249Z","shell.execute_reply":"2024-04-21T02:10:50.480366Z","shell.execute_reply.started":"2024-04-21T02:10:50.474399Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'input_ids': [230, 3, 88, 3, 22086, 956, 833, 46, 32, 189, 388, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [852, 3, 88, 19, 4134, 430, 388, 5, 1]}, {'input_ids': [27, 333, 3001, 5333, 1605, 14228, 77, 29, 23, 3, 12111, 3, 18450, 107, 28, 82, 4996, 17, 40, 108, 115, 40, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [27, 333, 12, 10065, 1605, 14883, 11113, 37, 1908, 32, 107, 28, 82, 385, 19665, 5, 1]}, {'input_ids': [24, 3, 22086, 956, 59, 1282, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [466, 19, 59, 1282, 5, 1]}, {'input_ids': [27, 584, 11165, 4974, 63, 36, 75, 2064, 3, 88, 19, 548, 23, 5295, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [27, 2994, 11790, 15, 63, 250, 3, 88, 19, 182, 5295, 5, 1]}, {'input_ids': [1687, 3, 6, 1028, 15, 9, 7, 3, 6, 20595, 3, 6, 9867, 3, 6, 11, 554, 11260, 29, 75, 584, 11165, 584, 19174, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [12358, 6, 1994, 6, 20595, 6, 9867, 6, 11, 8999, 33, 9231, 5, 1]}, {'input_ids': [80, 21167, 276, 6294, 228, 473, 3, 107, 3096, 23, 11, 46, 32, 189, 20, 4715, 3, 6, 584, 11165, 3001, 5781, 909, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [555, 1962, 25, 228, 473, 1095, 11, 430, 20, 8918, 6, 7570, 12, 5781, 909, 5, 1]}, {'input_ids': [3388, 3, 6, 27, 584, 11165, 59, 4680, 114, 3, 7436, 28, 119, 3202, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1875, 6, 27, 183, 59, 1086, 114, 48, 28, 119, 3567, 5, 1]}, {'input_ids': [276, 6294, 5607, 140, 13, 3, 9, 3, 17235, 113, 6572, 21, 10211, 21979, 336, 774, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [25, 5607, 140, 13, 3, 9, 4024, 113, 21042, 15, 26, 21, 10211, 21979, 336, 774, 5, 1]}, {'input_ids': [167, 1076, 584, 11165, 3, 32, 115, 2099, 1063, 81, 3, 7436, 3, 10, 3388, 3, 88, 584, 11165, 12, 114, 25, 3, 6, 258, 3, 88, 12361, 15403, 103, 15, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1377, 1076, 33, 4813, 81, 48, 10, 3, 99, 3, 88, 3475, 12, 114, 25, 6, 258, 3, 88, 1077, 405, 5, 1]}, {'input_ids': [27, 6264, 3, 6, 3, 12108, 3, 6, 24, 388, 23, 13, 82, 1565, 43, 612, 3, 12108, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [27, 6264, 6, 713, 6, 24, 186, 13, 82, 803, 43, 612, 78, 5, 1]}]\n"]}],"source":["print(train_dataset1[:10])"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T04:04:55.463993Z","iopub.status.busy":"2024-04-22T04:04:55.463635Z","iopub.status.idle":"2024-04-22T04:04:55.493637Z","shell.execute_reply":"2024-04-22T04:04:55.492683Z","shell.execute_reply.started":"2024-04-22T04:04:55.463965Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"742e9ff3dbe4463483ddbb6cf78a42fd","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T05:30:53.847815Z","iopub.status.busy":"2024-04-22T05:30:53.846988Z","iopub.status.idle":"2024-04-22T05:30:53.981635Z","shell.execute_reply":"2024-04-22T05:30:53.980564Z","shell.execute_reply.started":"2024-04-22T05:30:53.847782Z"},"trusted":true},"outputs":[],"source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset1 ,\n","    eval_dataset=val_dataset1,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T09:10:05.091117Z","iopub.status.busy":"2024-04-06T09:10:05.090085Z","iopub.status.idle":"2024-04-06T09:10:05.116983Z","shell.execute_reply":"2024-04-06T09:10:05.115787Z","shell.execute_reply.started":"2024-04-06T09:10:05.091079Z"},"trusted":true},"outputs":[],"source":["test_dataset1 = tokenized_dataset_formal_test.to_frame().to_dict(orient='records')"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T09:10:30.772875Z","iopub.status.busy":"2024-04-06T09:10:30.772425Z","iopub.status.idle":"2024-04-06T09:10:30.782646Z","shell.execute_reply":"2024-04-06T09:10:30.781298Z","shell.execute_reply.started":"2024-04-06T09:10:30.772841Z"},"trusted":true},"outputs":[],"source":["test2=[v for d in test_dataset1 for k, v in d.items()]"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T09:28:44.208833Z","iopub.status.busy":"2024-04-06T09:28:44.208413Z","iopub.status.idle":"2024-04-06T09:28:44.217722Z","shell.execute_reply":"2024-04-06T09:28:44.216628Z","shell.execute_reply.started":"2024-04-06T09:28:44.208801Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'input_ids': [27, 584, 11165, 10638, 11, 1692, 723, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [27, 114, 3, 27224, 11, 2419, 723, 5, 1]},\n"," {'input_ids': [262, 4, 3, 31, 7, 59, 107, 3, 88, 174, 12, 3, 75, 9270, 3, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [290, 31, 7, 1327, 3, 88, 523, 12, 483, 5, 1]}]"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["test2[:2]\n","# train_dataset1[:2]"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T09:13:54.188103Z","iopub.status.busy":"2024-04-06T09:13:54.187728Z","iopub.status.idle":"2024-04-06T09:13:54.193868Z","shell.execute_reply":"2024-04-06T09:13:54.192817Z","shell.execute_reply.started":"2024-04-06T09:13:54.188074Z"},"trusted":true},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T09:28:56.240167Z","iopub.status.busy":"2024-04-06T09:28:56.239224Z","iopub.status.idle":"2024-04-06T09:29:45.310093Z","shell.execute_reply":"2024-04-06T09:29:45.308540Z","shell.execute_reply.started":"2024-04-06T09:28:56.240112Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]}],"source":["test_predictions = trainer.predict(test2)"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T10:25:17.442015Z","iopub.status.busy":"2024-04-06T10:25:17.441558Z","iopub.status.idle":"2024-04-06T10:25:17.452771Z","shell.execute_reply":"2024-04-06T10:25:17.451114Z","shell.execute_reply.started":"2024-04-06T10:25:17.441982Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(array([[   0,  696, 3785, 1499, 1550,  270,    5,    1]]),\n"," array([    0,    27,   777, 10638,    11,  1692,   723,     5,     1,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0]))"]},"execution_count":139,"metadata":{},"output_type":"execute_result"}],"source":["b=output.numpy()\n","b,a"]},{"cell_type":"code","execution_count":141,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T10:25:26.544799Z","iopub.status.busy":"2024-04-06T10:25:26.544364Z","iopub.status.idle":"2024-04-06T10:25:26.556019Z","shell.execute_reply":"2024-04-06T10:25:26.554846Z","shell.execute_reply.started":"2024-04-06T10:25:26.544767Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Your input text goes here.'"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["a=test_predictions.predictions[0]\n","tokenizer.decode(b[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":123,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-06T10:18:56.930619Z","iopub.status.busy":"2024-04-06T10:18:56.930137Z","iopub.status.idle":"2024-04-06T10:18:57.873695Z","shell.execute_reply":"2024-04-06T10:18:57.872478Z","shell.execute_reply.started":"2024-04-06T10:18:56.930575Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"]}],"source":["from transformers import TFAutoModelForSeq2SeqLM\n","\n","# Define the directory where the model is saved\n","saved_model_dir = \"/kaggle/working/saved_model\"\n","\n","# Load the saved model\n","loaded_model = TFAutoModelForSeq2SeqLM.from_pretrained(saved_model_dir)\n"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T10:19:08.973497Z","iopub.status.busy":"2024-04-06T10:19:08.973052Z","iopub.status.idle":"2024-04-06T10:19:09.357862Z","shell.execute_reply":"2024-04-06T10:19:09.356633Z","shell.execute_reply.started":"2024-04-06T10:19:08.973464Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","# Load the saved model\n","loaded_model = AutoModelForSeq2SeqLM.from_pretrained(output_dir)"]},{"cell_type":"code","execution_count":131,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T10:22:40.248064Z","iopub.status.busy":"2024-04-06T10:22:40.247187Z","iopub.status.idle":"2024-04-06T10:22:40.510475Z","shell.execute_reply":"2024-04-06T10:22:40.509317Z","shell.execute_reply.started":"2024-04-06T10:22:40.248020Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[   0,  696, 3785, 1499, 1550,  270,    5,    1]])"]},"execution_count":131,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import AutoTokenizer\n","\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(output_dir)\n","\n","# Tokenize input text\n","input_text = \"Your input text goes here.\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n","\n","# Generate predictions\n","output = loaded_model.generate(input_ids)\n","output"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T10:03:02.837893Z","iopub.status.busy":"2024-04-06T10:03:02.837005Z","iopub.status.idle":"2024-04-06T10:03:02.845516Z","shell.execute_reply":"2024-04-06T10:03:02.844216Z","shell.execute_reply.started":"2024-04-06T10:03:02.837857Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<transformers.trainer_seq2seq.Seq2SeqTrainer at 0x7df02e467fa0>"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["trainer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T05:31:00.482964Z","iopub.status.busy":"2024-04-22T05:31:00.482297Z","iopub.status.idle":"2024-04-22T08:37:57.695201Z","shell.execute_reply":"2024-04-22T08:37:57.694061Z","shell.execute_reply.started":"2024-04-22T05:31:00.482933Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='13075' max='13075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13075/13075 3:06:55, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","      <th>Accuracy Log Reg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.568300</td>\n","      <td>0.528100</td>\n","      <td>84.057900</td>\n","      <td>71.563600</td>\n","      <td>83.979800</td>\n","      <td>83.990400</td>\n","      <td>14.266400</td>\n","      <td>0.747400</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.544900</td>\n","      <td>0.519130</td>\n","      <td>84.207800</td>\n","      <td>71.795600</td>\n","      <td>84.120700</td>\n","      <td>84.131300</td>\n","      <td>14.271000</td>\n","      <td>0.749600</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.534300</td>\n","      <td>0.514250</td>\n","      <td>84.308300</td>\n","      <td>72.002000</td>\n","      <td>84.228000</td>\n","      <td>84.237600</td>\n","      <td>14.279400</td>\n","      <td>0.753000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.521900</td>\n","      <td>0.511729</td>\n","      <td>84.350200</td>\n","      <td>72.089400</td>\n","      <td>84.269200</td>\n","      <td>84.277900</td>\n","      <td>14.284500</td>\n","      <td>0.752600</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.517900</td>\n","      <td>0.510852</td>\n","      <td>84.371500</td>\n","      <td>72.107800</td>\n","      <td>84.288400</td>\n","      <td>84.297500</td>\n","      <td>14.280100</td>\n","      <td>0.754400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'rouge1': 84.05785061785366, 'rouge2': 71.56357594133377, 'rougeL': 83.97981985363651, 'rougeLsum': 83.99037070366552, 'gen_len': 14.266389327212739, 'accuracy_log_reg': 0.7474298283364414}\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'rouge1': 84.20782128327714, 'rouge2': 71.7956439443813, 'rougeL': 84.1206635824782, 'rougeLsum': 84.13133374942984, 'gen_len': 14.270979773346722, 'accuracy_log_reg': 0.7496294171089752}\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'rouge1': 84.308253379878, 'rouge2': 72.00201077868591, 'rougeL': 84.22801475402373, 'rougeLsum': 84.237629031623, 'gen_len': 14.279395591259025, 'accuracy_log_reg': 0.753024434562234}\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'rouge1': 84.35022059345305, 'rouge2': 72.08942292275557, 'rougeL': 84.26918500427345, 'rougeLsum': 84.27788607004096, 'gen_len': 14.284464208865298, 'accuracy_log_reg': 0.752641897384402}\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'rouge1': 84.37152575886486, 'rouge2': 72.10782428836092, 'rougeL': 84.28838568624523, 'rougeLsum': 84.29751984774867, 'gen_len': 14.28011284846746, 'accuracy_log_reg': 0.7543633146846459}\n"]},{"data":{"text/plain":["TrainOutput(global_step=13075, training_loss=0.5423579893969213, metrics={'train_runtime': 11215.9199, 'train_samples_per_second': 37.29, 'train_steps_per_second': 1.166, 'total_flos': 2.04372631206144e+16, 'train_loss': 0.5423579893969213, 'epoch': 5.0})"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T08:37:58.169759Z","iopub.status.busy":"2024-04-22T08:37:58.169383Z","iopub.status.idle":"2024-04-22T08:37:58.176699Z","shell.execute_reply":"2024-04-22T08:37:58.175709Z","shell.execute_reply.started":"2024-04-22T08:37:58.169729Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["training complete\n"]}],"source":["print(\"training complete\")"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T08:37:58.193625Z","iopub.status.busy":"2024-04-22T08:37:58.192864Z","iopub.status.idle":"2024-04-22T08:37:58.200150Z","shell.execute_reply":"2024-04-22T08:37:58.198918Z","shell.execute_reply.started":"2024-04-22T08:37:58.193589Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["testing\n"]}],"source":["print(\"testing\")"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T08:37:58.205173Z","iopub.status.busy":"2024-04-22T08:37:58.204797Z","iopub.status.idle":"2024-04-22T08:37:58.212042Z","shell.execute_reply":"2024-04-22T08:37:58.210986Z","shell.execute_reply.started":"2024-04-22T08:37:58.205140Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["testing\n"]}],"source":["print(\"testing\")"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T08:58:07.572296Z","iopub.status.busy":"2024-04-22T08:58:07.571365Z","iopub.status.idle":"2024-04-22T08:58:14.209728Z","shell.execute_reply":"2024-04-22T08:58:14.208661Z","shell.execute_reply.started":"2024-04-22T08:58:07.572259Z"},"trusted":true},"outputs":[{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/Pushparaj20/t5-base-finetuned/commit/44b89c715b9a8a5b1e70ed3ad12450c3b31eb150', commit_message='Pushparaj20/formal_transfer', commit_description='', oid='44b89c715b9a8a5b1e70ed3ad12450c3b31eb150', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub(\"Pushparaj20/formal_transfer\")"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T08:58:14.212346Z","iopub.status.busy":"2024-04-22T08:58:14.211780Z","iopub.status.idle":"2024-04-22T08:58:15.128519Z","shell.execute_reply":"2024-04-22T08:58:15.127413Z","shell.execute_reply.started":"2024-04-22T08:58:14.212319Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","# Load the model from the model hu\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"Pushparaj20/t5-base-finetuned\")"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T08:55:00.671910Z","iopub.status.busy":"2024-04-22T08:55:00.671145Z","iopub.status.idle":"2024-04-22T08:55:00.693085Z","shell.execute_reply":"2024-04-22T08:55:00.692044Z","shell.execute_reply.started":"2024-04-22T08:55:00.671875Z"},"trusted":true},"outputs":[],"source":["test_dataset1 = tokenized_dataset_formal_test.to_frame().to_dict(orient='records')"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T08:55:01.505063Z","iopub.status.busy":"2024-04-22T08:55:01.504693Z","iopub.status.idle":"2024-04-22T08:55:01.512858Z","shell.execute_reply":"2024-04-22T08:55:01.511373Z","shell.execute_reply.started":"2024-04-22T08:55:01.505031Z"},"trusted":true},"outputs":[],"source":["test2=[v for d in test_dataset1 for k, v in d.items()]"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T06:58:54.146325Z","iopub.status.busy":"2024-04-21T06:58:54.145322Z","iopub.status.idle":"2024-04-21T06:58:54.151788Z","shell.execute_reply":"2024-04-21T06:58:54.150672Z","shell.execute_reply.started":"2024-04-21T06:58:54.146290Z"},"trusted":true},"outputs":[],"source":["t=test2[0][\"input_ids\"]"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T06:58:58.134432Z","iopub.status.busy":"2024-04-21T06:58:58.134067Z","iopub.status.idle":"2024-04-21T06:58:58.142227Z","shell.execute_reply":"2024-04-21T06:58:58.141063Z","shell.execute_reply.started":"2024-04-21T06:58:58.134405Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[27, 584, 11165, 10638, 11, 1692, 723, 3, 5, 1, 1]"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["t"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T08:55:08.813054Z","iopub.status.busy":"2024-04-22T08:55:08.811966Z","iopub.status.idle":"2024-04-22T08:55:09.266344Z","shell.execute_reply":"2024-04-22T08:55:09.265182Z","shell.execute_reply.started":"2024-04-22T08:55:08.813007Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 696, 3785, 1499, 1550,  270,    5,    1]])\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"data":{"text/plain":["'Your input text goes here.'"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["input_text = \"Your input text goes here.\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n","print(input_ids)\n","\n","# Generate predictions\n","output = model.generate(input_ids)\n","b=output.numpy()\n","tokenizer.decode(b[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T07:01:13.353868Z","iopub.status.busy":"2024-04-21T07:01:13.353464Z","iopub.status.idle":"2024-04-21T07:01:13.363350Z","shell.execute_reply":"2024-04-21T07:01:13.362165Z","shell.execute_reply.started":"2024-04-21T07:01:13.353838Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Your input text goes here.'"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T07:32:40.945463Z","iopub.status.busy":"2024-04-21T07:32:40.945100Z","iopub.status.idle":"2024-04-21T07:32:40.951926Z","shell.execute_reply":"2024-04-21T07:32:40.950756Z","shell.execute_reply.started":"2024-04-21T07:32:40.945438Z"},"trusted":true},"outputs":[],"source":["new=[]"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T07:36:26.176402Z","iopub.status.busy":"2024-04-21T07:36:26.175478Z","iopub.status.idle":"2024-04-21T07:36:32.423346Z","shell.execute_reply":"2024-04-21T07:36:32.422235Z","shell.execute_reply.started":"2024-04-21T07:36:26.176368Z"},"trusted":true},"outputs":[],"source":["for i in range(0,10):\n","    o=model.generate(input_ids=torch.tensor([test2[i][\"input_ids\"]]))\n","    new.append(o)\n","    \n","    \n"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T07:37:00.922122Z","iopub.status.busy":"2024-04-21T07:37:00.921267Z","iopub.status.idle":"2024-04-21T07:37:00.930360Z","shell.execute_reply":"2024-04-21T07:37:00.929165Z","shell.execute_reply.started":"2024-04-21T07:37:00.922086Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[    0,    27,   133,   167,   952,    59,  2902,    21,   376,     6,\n","          2199,    27,   317, 31297,   133,    36,     8,   167,  5250,   166]])"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["o"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T07:37:44.966569Z","iopub.status.busy":"2024-04-21T07:37:44.965720Z","iopub.status.idle":"2024-04-21T07:37:44.995761Z","shell.execute_reply":"2024-04-21T07:37:44.994600Z","shell.execute_reply.started":"2024-04-21T07:37:44.966539Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['I enjoy rhythm and blues music.']\n","[\"There's nothing he needs to change.\"]\n","['It does not exist.']\n","[\"Mine is book by Steve Martin called 'The Pleasure of My Company'.\"]\n","['What differentiates a mosquitoo from a blonde?']\n","[\"They're very attractive. Also, that's a good song.\"]\n","['I do not think Beyonce can sing, dance, or perform. You mentioned Rih']\n","['I was unaware that you were in law enforcement, as well.']\n","[\"I call to say 'I love you\"]\n","['I would most likely not vote for him, although I think Melanie would be the most attractive first']\n","['I do not hate him.']\n","['Youtube.com also features many of the most funny ads.']\n","['I enjoy watching my companions attempt to role-play with them.']\n","['Some of my favorite television series are Monk, the Duke of Hazard, Miami Vice']\n","['I have a desire to produce videos on Full Metal Alchemist.']\n","['I would travel to that location and physically assault you at this very moment, however, I am']\n","['Your mother is so unintelligent that she was hit by a cup and told']\n","['You should be creative and find something to challenge us.']\n","['I am watching it right now.']\n","['I do not know; the person who invented the name had attention deficit disorder.']\n","['I think, rather, that they are not very smart on this topic.']\n","['Of course it is Oprah, because she has been receiving better advice for a longer']\n","['That is the key point, that you fell asleep.']\n","['A brunette girl, a blonde, and girl with red hair walk down a street']\n","['That is funny. Men need to be a part of everything.']\n","[\"In point of fact, Chris's appearance looks like the encouraging appearance at a Genevie\"]\n","['In my time, Emo was a comedian.']\n","['Moriarty and so forth, but what character did the Peruvian actor portray?']\n","['What did the beaver say to the log?']\n","['I miss Aaliyah, she was a great actress.']\n","[\"I don't think he is in love with her.\"]\n","['Your mother is so stupid that she tried to drown a fish.']\n","['The is very funny, but in a sick vein.']\n","['I do not hate him but he makes me feel unpleasant.']\n","['It offends men equally.']\n","['I love both of those women, especially Aaliyah. They are deceased but still watch over']\n","['Do you feel than three members is a good number for a band?']\n","['Your mother is really unattractive.']\n","['Refrain from trying to make an impression on her; should she favor you, she will']\n","[\"No, we just aren't very well-understood.\"]\n","[\"I agree with the assessment of beauty and enjoy reading the lady on 'Love Hina.\"]\n","['Yes, I am using Aries, you should try that one.']\n","['I previously played the flute, but quickly became enamored with the sa']\n","['I have met a lot of celebrities while working on yachts for the past 30 years.']\n","[\"Your mother's stupidity is so excessive she sold her car to acquire money for gasoline.\"]\n","['Why is a hemorrhoids not the same as an asteroid?']\n","['My friend said that if you learn the simplest four notes, you will be able']\n","['What exactly are you stating?']\n","['Yes, I did hear the information about Bjork and Chaney.']\n","[\"And the blonde woman replied, 'Wonderful, I am already assigned my first\"]\n","['Those kind of artists give the hip-hop genre a bad name.']\n","[\"I duck behind the sofa as I say, 'I don't like living here'\"]\n","[\"Until the show's next season.\"]\n","['My little brother would ask a question like that.']\n","['Tell me your entertaining dreams, ladies and guys!']\n","[\"I would be favorably spending a summer with him on 'Brokeback Mountain.\"]\n","['You know the beta team still wants to answer this.']\n","['Anakin and Queen Amadala, of course.']\n","[\"And say it again, 'From Buffalo, NY.'\"]\n","['The chorus sounds something like that.']\n","['Rap music contains too much explicit content.']\n","['Paula seems to take a liking to everyone this week.']\n","[\"Tell him you are pregnant with someone else's child.\"]\n","['The two boys have strange, redneck characteristics such as playing with glue inhalers.']\n","['I am assuming that you are a republican.']\n","['I think he is an extremely unkempt little man, who looks greas']\n","['I do not need to be a homosexual.']\n","[\"'The Girl,' 'The Girl,' 'Twin Peaks,\"]\n","['Pluto, for an older man, that is really interesting.']\n","['Naturally, she is attractive, her husband does not care for her, and she is so weak']\n","['I am constantly inquiring because people behave as though they are no longer interested in them.']\n","['I love it because I love the show.']\n","['However, I cannot find any information concerning that.']\n","['I imagine he would be a better option for you.']\n","[\"The Beastie Boys have a song containing the lyrics 'I ate the\"]\n","['I enjoy rhythm and blues music.']\n","['I enjoy rhythm and blues music.']\n","[\"There's nothing he needs to change.\"]\n","['It does not exist.']\n","[\"Mine is book by Steve Martin called 'The Pleasure of My Company'.\"]\n","['What differentiates a mosquitoo from a blonde?']\n","[\"They're very attractive. Also, that's a good song.\"]\n","['I do not think Beyonce can sing, dance, or perform. You mentioned Rih']\n","['I was unaware that you were in law enforcement, as well.']\n","[\"I call to say 'I love you\"]\n","['I would most likely not vote for him, although I think Melanie would be the most attractive first']\n","['I enjoy rhythm and blues music.']\n","[\"There's nothing he needs to change.\"]\n","['It does not exist.']\n","[\"Mine is book by Steve Martin called 'The Pleasure of My Company'.\"]\n","['What differentiates a mosquitoo from a blonde?']\n","[\"They're very attractive. Also, that's a good song.\"]\n","['I do not think Beyonce can sing, dance, or perform. You mentioned Rih']\n","['I was unaware that you were in law enforcement, as well.']\n","[\"I call to say 'I love you\"]\n","['I would most likely not vote for him, although I think Melanie would be the most attractive first']\n"]}],"source":["# decoded_outputs = tokenizer.batch_decode(new, skip_special_tokens=True)\n","\n","# Print the decoded outputs\n","for output in new:\n","    print(tokenizer.batch_decode(output, skip_special_tokens=True))"]},{"cell_type":"code","execution_count":104,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T07:50:05.359130Z","iopub.status.busy":"2024-04-21T07:50:05.358363Z","iopub.status.idle":"2024-04-21T07:50:05.365248Z","shell.execute_reply":"2024-04-21T07:50:05.364041Z","shell.execute_reply.started":"2024-04-21T07:50:05.359099Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["hello\n"]}],"source":["print(\"hello\")"]},{"cell_type":"code","execution_count":125,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T09:26:40.192469Z","iopub.status.busy":"2024-04-22T09:26:40.192091Z","iopub.status.idle":"2024-04-22T09:26:40.550177Z","shell.execute_reply":"2024-04-22T09:26:40.548986Z","shell.execute_reply.started":"2024-04-22T09:26:40.192442Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["File 'weight.pkl' downloaded successfully to 'logreg'.\n"]}],"source":["import os\n","import requests\n","\n","# Define the repository and file names\n","repo_name = \"Pushparaj20/t5-base-finetuned\"  # Replace with your actual username and repository name\n","file_name = \"weight.pkl\"\n","\n","# Construct the URL to fetch the file from the repository\n","file_url = f\"https://huggingface.co/{repo_name}/resolve/main/{file_name}\"\n","\n","# Define the directory where you want to save the file locally\n","output_dir = \"logreg\"  # Choose a directory name\n","\n","# Make a GET request to download the file\n","response = requests.get(file_url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Create the output directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","    # Write the file content to disk\n","    with open(os.path.join(output_dir, file_name), \"wb\") as file:\n","        file.write(response.content)\n","    print(f\"File '{file_name}' downloaded successfully to '{output_dir}'.\")\n","else:\n","    print(f\"Failed to download '{file_name}' from '{repo_name}'. Status code: {response.status_code}\")\n"]},{"cell_type":"code","execution_count":147,"metadata":{"execution":{"iopub.execute_input":"2024-04-21T09:15:59.275585Z","iopub.status.busy":"2024-04-21T09:15:59.274857Z","iopub.status.idle":"2024-04-21T09:15:59.283556Z","shell.execute_reply":"2024-04-21T09:15:59.281952Z","shell.execute_reply.started":"2024-04-21T09:15:59.275547Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'logreg_weights.pkl'"]},"execution_count":147,"metadata":{},"output_type":"execute_result"}],"source":["weights_file\n"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T09:06:39.774918Z","iopub.status.busy":"2024-04-22T09:06:39.774569Z","iopub.status.idle":"2024-04-22T09:06:39.793392Z","shell.execute_reply":"2024-04-22T09:06:39.792487Z","shell.execute_reply.started":"2024-04-22T09:06:39.774892Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n","                 TfidfVectorizer(max_df=0.85, max_features=200000,\n","                                 ngram_range=(1, 3))),\n","                (&#x27;classifier&#x27;, LogisticRegression(max_iter=5000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n","                 TfidfVectorizer(max_df=0.85, max_features=200000,\n","                                 ngram_range=(1, 3))),\n","                (&#x27;classifier&#x27;, LogisticRegression(max_iter=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.85, max_features=200000, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5000)</pre></div></div></div></div></div></div></div>"],"text/plain":["Pipeline(steps=[('vectorizer',\n","                 TfidfVectorizer(max_df=0.85, max_features=200000,\n","                                 ngram_range=(1, 3))),\n","                ('classifier', LogisticRegression(max_iter=5000))])"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["pipeline"]},{"cell_type":"code","execution_count":122,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T09:23:51.366575Z","iopub.status.busy":"2024-04-22T09:23:51.365602Z","iopub.status.idle":"2024-04-22T09:23:54.627835Z","shell.execute_reply":"2024-04-22T09:23:54.626677Z","shell.execute_reply.started":"2024-04-22T09:23:51.366530Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'dict'>\n","[('00', -0.31355464842683434), ('00 450', 0.0651834349662771), ('00 450 00', 0.0651834349662771), ('00 92', -0.0008144601026945803), ('00 cad', 0.12968708244671773), ('00 central', -0.0062241793331848745), ('00 central time', -0.0062241793331848745), ('00 eastern', 0.019410039255864337), ('00 eastern time', 0.019410039255864337), ('00 english', -0.02147050676313063)]\n"]}],"source":["import joblib\n","\n","# Load the weights from the file\n","loaded_weights = joblib.load('logreg_weights.pkl')\n","\n","# Print the type of loaded weights and the first few entries\n","print(type(loaded_weights))\n","print(list(loaded_weights.items())[:10])  # Print the first 10 items\n","\n","\n","# Check if the structure is similar to the weights dictionary\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T09:32:31.766322Z","iopub.status.busy":"2024-04-22T09:32:31.765686Z","iopub.status.idle":"2024-04-22T09:32:34.910359Z","shell.execute_reply":"2024-04-22T09:32:34.909399Z","shell.execute_reply.started":"2024-04-22T09:32:31.766288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Transformed Sentence: I VBP have a NN that he has a NN on you .\n"]}],"source":["import joblib\n","from nltk.tokenize import word_tokenize\n","from nltk import pos_tag\n","from nltk.stem import PorterStemmer\n","\n","# Load the weights from the file\n","weights_file = 'logreg/weight.pkl'\n","loaded_weights = joblib.load(weights_file)\n","\n","# Define a sample sentence\n","sentence = \"s.\"\n","\n","# Specify the value of is_formal\n","is_formal = True  # Example value\n","stemmer = SnowballStemmer(\"english\")\n","\n","# Define the function to replace words with POS tags\n","def replace_with_pos_tags(sentence, weights, is_formal):\n","    tokens = word_tokenize(sentence)\n","    stemmed_tokens = [stemmer.stem(token) for token in tokens]  # Stem tokens\n","    pos_tags = pos_tag(tokens)  # Use original tokens for POS tagging\n","    replaced_sentence = []\n","\n","    # Calculate N as described\n","    N = len(stemmed_tokens) // 4\n","\n","    # Filter out stop words and stem them\n","    tokens_without_stopwords = [stemmer.stem(token) for token in tokens if token.lower() not in stop_words]\n","\n","    # Sort stemmed tokens by weight\n","    sorted_tokens = sorted(tokens_without_stopwords, key=lambda x: abs(weights.get(x, 0)), reverse=True)\n","\n","    # Extract N tokens with highest absolute weights\n","    top_N_tokens = sorted_tokens[:N]\n","\n","    for token, tag in pos_tags:\n","        stemmed_token = stemmer.stem(token)\n","        if stemmed_token in top_N_tokens:\n","            weight = abs(weights.get(stemmed_token, 0))\n","            if (is_formal and weight >= 0.01) or (not is_formal and weight >= 0.02):\n","                replaced_sentence.append(tag)\n","            else:\n","                replaced_sentence.append(token)\n","        else:\n","            replaced_sentence.append(token)\n","\n","    return ' '.join(replaced_sentence)\n","\n","# Call the function with loaded weights, sample sentence, and is_formal value\n","transformed_sentence = replace_with_pos_tags(sentence, loaded_weights, is_formal)\n","\n","# Print the transformed sentence\n","print(\"Transformed Sentence:\", transformed_sentence)\n"]},{"cell_type":"code","execution_count":128,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T09:29:39.568463Z","iopub.status.busy":"2024-04-22T09:29:39.568058Z","iopub.status.idle":"2024-04-22T09:29:40.518730Z","shell.execute_reply":"2024-04-22T09:29:40.517572Z","shell.execute_reply.started":"2024-04-22T09:29:39.568430Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","# Load the model from the model hu\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"Pushparaj20/t5-base-finetuned\")"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T09:32:38.076490Z","iopub.status.busy":"2024-04-22T09:32:38.075745Z","iopub.status.idle":"2024-04-22T09:32:38.814660Z","shell.execute_reply":"2024-04-22T09:32:38.813634Z","shell.execute_reply.started":"2024-04-22T09:32:38.076456Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[   27,   584, 11165,    43,     3,     9,     3, 17235,    24,     3,\n","            88,    65,     3,     9,     3, 17235,    30,    25,     3,     5,\n","             1]])\n"]},{"data":{"text/plain":["'I still have a feeling that he has a crush on you.'"]},"execution_count":135,"metadata":{},"output_type":"execute_result"}],"source":["\n","input_ids = tokenizer(transformed_sentence, return_tensors=\"pt\").input_ids\n","print(input_ids)\n","\n","# Generate predictions\n","output = model.generate(input_ids)\n","b=output.numpy()\n","tokenizer.decode(b[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T09:25:22.082754Z","iopub.status.busy":"2024-04-22T09:25:22.082367Z","iopub.status.idle":"2024-04-22T09:25:29.018853Z","shell.execute_reply":"2024-04-22T09:25:29.017735Z","shell.execute_reply.started":"2024-04-22T09:25:22.082723Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['weight.pkl']"]},"execution_count":124,"metadata":{},"output_type":"execute_result"}],"source":["weights_file = \"weight.pkl\"\n","joblib.dump(weights, weights_file)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4742002,"sourceId":8042803,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
