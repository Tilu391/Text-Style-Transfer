{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8085125,"sourceType":"datasetVersion","datasetId":4772606}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-10T18:41:33.850129Z","iopub.execute_input":"2024-04-10T18:41:33.850474Z","iopub.status.idle":"2024-04-10T18:41:34.639184Z","shell.execute_reply.started":"2024-04-10T18:41:33.850447Z","shell.execute_reply":"2024-04-10T18:41:34.638195Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/act-pas/active_passive_full_cleaned.tsv\n/kaggle/input/act-pas/active_passive.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:41:34.640726Z","iopub.execute_input":"2024-04-10T18:41:34.641133Z","iopub.status.idle":"2024-04-10T18:41:34.645700Z","shell.execute_reply.started":"2024-04-10T18:41:34.641109Z","shell.execute_reply":"2024-04-10T18:41:34.644652Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:41:34.670102Z","iopub.execute_input":"2024-04-10T18:41:34.670358Z","iopub.status.idle":"2024-04-10T18:41:36.371657Z","shell.execute_reply.started":"2024-04-10T18:41:34.670337Z","shell.execute_reply":"2024-04-10T18:41:36.370480Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/act-pas/active_passive_full_cleaned.tsv\", sep=\"\\t\", header=None)\n\ndf.columns = [\"Passive\", \"Active\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:41:36.373772Z","iopub.execute_input":"2024-04-10T18:41:36.374710Z","iopub.status.idle":"2024-04-10T18:41:40.007514Z","shell.execute_reply.started":"2024-04-10T18:41:36.374658Z","shell.execute_reply":"2024-04-10T18:41:40.006731Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:41:40.008539Z","iopub.execute_input":"2024-04-10T18:41:40.008808Z","iopub.status.idle":"2024-04-10T18:41:40.022497Z","shell.execute_reply.started":"2024-04-10T18:41:40.008785Z","shell.execute_reply":"2024-04-10T18:41:40.021741Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                             Passive  \\\n0  In cases of dispute the matter shall be resolv...   \n1  A dispute on this point shall be determined in...   \n2  This matter shall be resolved by the judgement...   \n3  If any Freeman shall die Intestate, his chatte...   \n4  All evil customs connected with forests and Wa...   \n\n                                              Active  \n0  In cases of dispute the judgement of the twent...  \n1  The judgement of equals shall determine in the...  \n2  The judgement of his equals shall resolve this...  \n3  If any Freeman shall die Intestate, the hands ...  \n4  Twelve sworn Knights of the same County chosen...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Passive</th>\n      <th>Active</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In cases of dispute the matter shall be resolv...</td>\n      <td>In cases of dispute the judgement of the twent...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A dispute on this point shall be determined in...</td>\n      <td>The judgement of equals shall determine in the...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This matter shall be resolved by the judgement...</td>\n      <td>The judgement of his equals shall resolve this...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If any Freeman shall die Intestate, his chatte...</td>\n      <td>If any Freeman shall die Intestate, the hands ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>All evil customs connected with forests and Wa...</td>\n      <td>Twelve sworn Knights of the same County chosen...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip uninstall -y transformers\n!pip install transformers\n!pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:42:02.156288Z","iopub.execute_input":"2024-04-10T18:42:02.157128Z","iopub.status.idle":"2024-04-10T18:42:35.011340Z","shell.execute_reply.started":"2024-04-10T18:42:02.157087Z","shell.execute_reply":"2024-04-10T18:42:35.010168Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting transformers\n  Using cached transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nUsing cached transformers-4.39.3-py3-none-any.whl (8.8 MB)\nInstalling collected packages: transformers\nSuccessfully installed transformers-4.39.3\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nmodel_checkpoint = \"t5-small\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:42:35.013322Z","iopub.execute_input":"2024-04-10T18:42:35.013629Z","iopub.status.idle":"2024-04-10T18:42:52.378839Z","shell.execute_reply.started":"2024-04-10T18:42:35.013601Z","shell.execute_reply":"2024-04-10T18:42:52.377785Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-04-10 18:42:41.028030: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-10 18:42:41.028168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-10 18:42:41.121263: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db94d6f9a8aa4efdaf70fd508574a98f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e78be96e956a45ff89e6ca4eae11eab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a324975c334eb691e345fd68a449d9"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\nmodel_name = model_checkpoint.split(\"/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-pas2act\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=4,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:42:52.380577Z","iopub.execute_input":"2024-04-10T18:42:52.381127Z","iopub.status.idle":"2024-04-10T18:42:52.498230Z","shell.execute_reply.started":"2024-04-10T18:42:52.381098Z","shell.execute_reply":"2024-04-10T18:42:52.496831Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:42:55.515302Z","iopub.execute_input":"2024-04-10T18:42:55.516204Z","iopub.status.idle":"2024-04-10T18:43:08.560502Z","shell.execute_reply.started":"2024-04-10T18:42:55.516165Z","shell.execute_reply":"2024-04-10T18:43:08.559321Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from evaluate import load\n!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:43:10.471396Z","iopub.execute_input":"2024-04-10T18:43:10.472002Z","iopub.status.idle":"2024-04-10T18:43:26.304424Z","shell.execute_reply.started":"2024-04-10T18:43:10.471958Z","shell.execute_reply":"2024-04-10T18:43:26.303273Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a8df2d097266b23c34a6b066d1e27218b331c618e7a8007154e3d9fc299975c8\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"metric1 = load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:43:26.306773Z","iopub.execute_input":"2024-04-10T18:43:26.307064Z","iopub.status.idle":"2024-04-10T18:43:26.792830Z","shell.execute_reply.started":"2024-04-10T18:43:26.307037Z","shell.execute_reply":"2024-04-10T18:43:26.792078Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"561f2a28a2864e1bab125a3d714eb1e9"}},"metadata":{}}]},{"cell_type":"code","source":"metric2 = load(\"bleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:43:26.793856Z","iopub.execute_input":"2024-04-10T18:43:26.794134Z","iopub.status.idle":"2024-04-10T18:43:30.881208Z","shell.execute_reply.started":"2024-04-10T18:43:26.794111Z","shell.execute_reply":"2024-04-10T18:43:30.880301Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d6289e69a2b4bbda273f4a622f07828"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bfd6bdba2494fe4b30611e680a4d40a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4e7dbf1a53349239428ea38b62c16b6"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:43:35.129752Z","iopub.execute_input":"2024-04-10T18:43:35.130562Z","iopub.status.idle":"2024-04-10T18:43:35.823533Z","shell.execute_reply.started":"2024-04-10T18:43:35.130533Z","shell.execute_reply":"2024-04-10T18:43:35.822720Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd7db953a4ca4b7787184e19b88a50e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cedc8335c71e4594858bbab38dfae6a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c86e3a847c454a31805542337b80613d"}},"metadata":{}}]},{"cell_type":"code","source":"df2 = pd.read_csv(\"/kaggle/input/act-pas/active_passive.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:44:18.816639Z","iopub.execute_input":"2024-04-10T18:44:18.817324Z","iopub.status.idle":"2024-04-10T18:44:18.829027Z","shell.execute_reply.started":"2024-04-10T18:44:18.817291Z","shell.execute_reply":"2024-04-10T18:44:18.828047Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:44:26.475222Z","iopub.execute_input":"2024-04-10T18:44:26.476252Z","iopub.status.idle":"2024-04-10T18:44:26.486842Z","shell.execute_reply.started":"2024-04-10T18:44:26.476217Z","shell.execute_reply":"2024-04-10T18:44:26.485883Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                    Active                            Passive\n0        He reads a novel.                   A novel is read.\n1   He does not cook food.         Food is not cooked by him.\n2  Does he purchase books?  Are books being purchased by him?\n3        They grow plants.          Plants are grown by them.\n4          She teaches me.                I am taught by her.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Active</th>\n      <th>Passive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He reads a novel.</td>\n      <td>A novel is read.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>He does not cook food.</td>\n      <td>Food is not cooked by him.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Does he purchase books?</td>\n      <td>Are books being purchased by him?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They grow plants.</td>\n      <td>Plants are grown by them.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>She teaches me.</td>\n      <td>I am taught by her.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1 = pd.concat([df2, df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:50:26.776058Z","iopub.execute_input":"2024-04-10T18:50:26.776474Z","iopub.status.idle":"2024-04-10T18:50:26.797083Z","shell.execute_reply.started":"2024-04-10T18:50:26.776442Z","shell.execute_reply":"2024-04-10T18:50:26.796316Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:50:26.969346Z","iopub.execute_input":"2024-04-10T18:50:26.969668Z","iopub.status.idle":"2024-04-10T18:50:26.980844Z","shell.execute_reply.started":"2024-04-10T18:50:26.969644Z","shell.execute_reply":"2024-04-10T18:50:26.979794Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"                                                   Active  \\\n0                                       He reads a novel.   \n1                                  He does not cook food.   \n2                                 Does he purchase books?   \n3                                       They grow plants.   \n4                                         She teaches me.   \n...                                                   ...   \n472670  An adopted daughter, whom she had rescued from...   \n472671  The country well should pay such a servant of ...   \n472672  Governor Andrew, of Massachusetts sent to me f...   \n472673  General Hunter employed her, and I think by ge...   \n472674  Since that time, Uri Gilbert, Esq ., of this c...   \n\n                                                  Passive  \n0                                        A novel is read.  \n1                              Food is not cooked by him.  \n2                       Are books being purchased by him?  \n3                               Plants are grown by them.  \n4                                     I am taught by her.  \n...                                                   ...  \n472670  She was led into the church by an adopted daug...  \n472671  Such a servant of the country should be well p...  \n472672  Harriet was sent to me from Boston by Governor...  \n472673  She was employed by General Hunter, and I thin...  \n472674  Since that time, he has been employed as coach...  \n\n[472675 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Active</th>\n      <th>Passive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He reads a novel.</td>\n      <td>A novel is read.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>He does not cook food.</td>\n      <td>Food is not cooked by him.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Does he purchase books?</td>\n      <td>Are books being purchased by him?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They grow plants.</td>\n      <td>Plants are grown by them.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>She teaches me.</td>\n      <td>I am taught by her.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>472670</th>\n      <td>An adopted daughter, whom she had rescued from...</td>\n      <td>She was led into the church by an adopted daug...</td>\n    </tr>\n    <tr>\n      <th>472671</th>\n      <td>The country well should pay such a servant of ...</td>\n      <td>Such a servant of the country should be well p...</td>\n    </tr>\n    <tr>\n      <th>472672</th>\n      <td>Governor Andrew, of Massachusetts sent to me f...</td>\n      <td>Harriet was sent to me from Boston by Governor...</td>\n    </tr>\n    <tr>\n      <th>472673</th>\n      <td>General Hunter employed her, and I think by ge...</td>\n      <td>She was employed by General Hunter, and I thin...</td>\n    </tr>\n    <tr>\n      <th>472674</th>\n      <td>Since that time, Uri Gilbert, Esq ., of this c...</td>\n      <td>Since that time, he has been employed as coach...</td>\n    </tr>\n  </tbody>\n</table>\n<p>472675 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1['Passive_word_count'] = df1['Passive'].apply(lambda x: len(x.split()))\n\n# Filter out rows where the number of words in \"Active\" is more than 20\ndf_filtered = df1[df1['Passive_word_count'] <= 16]\n\n# Drop the temporary column 'Active_word_count'\ndf1 = df_filtered.drop(columns=['Passive_word_count'])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:50:27.139393Z","iopub.execute_input":"2024-04-10T18:50:27.139724Z","iopub.status.idle":"2024-04-10T18:50:28.148690Z","shell.execute_reply.started":"2024-04-10T18:50:27.139698Z","shell.execute_reply":"2024-04-10T18:50:28.147671Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:50:28.150252Z","iopub.execute_input":"2024-04-10T18:50:28.150547Z","iopub.status.idle":"2024-04-10T18:50:28.161811Z","shell.execute_reply.started":"2024-04-10T18:50:28.150522Z","shell.execute_reply":"2024-04-10T18:50:28.160753Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                                   Active  \\\n0                                       He reads a novel.   \n1                                  He does not cook food.   \n2                                 Does he purchase books?   \n3                                       They grow plants.   \n4                                         She teaches me.   \n...                                                   ...   \n472662  But to - day, our senatorial charlatans and th...   \n472667  A roar of satisfaction from the crowd below re...   \n472669  Various names among her Southern friends knew ...   \n472671  The country well should pay such a servant of ...   \n472674  Since that time, Uri Gilbert, Esq ., of this c...   \n\n                                                  Passive  \n0                                        A novel is read.  \n1                              Food is not cooked by him.  \n2                       Are books being purchased by him?  \n3                               Plants are grown by them.  \n4                                     I am taught by her.  \n...                                                   ...  \n472662  But to-day, what is politically proposed by ou...  \n472667  This was responded to by a roar of satisfactio...  \n472669  Harriet was known by various names among her S...  \n472671  Such a servant of the country should be well p...  \n472674  Since that time, he has been employed as coach...  \n\n[157481 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Active</th>\n      <th>Passive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He reads a novel.</td>\n      <td>A novel is read.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>He does not cook food.</td>\n      <td>Food is not cooked by him.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Does he purchase books?</td>\n      <td>Are books being purchased by him?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They grow plants.</td>\n      <td>Plants are grown by them.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>She teaches me.</td>\n      <td>I am taught by her.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>472662</th>\n      <td>But to - day, our senatorial charlatans and th...</td>\n      <td>But to-day, what is politically proposed by ou...</td>\n    </tr>\n    <tr>\n      <th>472667</th>\n      <td>A roar of satisfaction from the crowd below re...</td>\n      <td>This was responded to by a roar of satisfactio...</td>\n    </tr>\n    <tr>\n      <th>472669</th>\n      <td>Various names among her Southern friends knew ...</td>\n      <td>Harriet was known by various names among her S...</td>\n    </tr>\n    <tr>\n      <th>472671</th>\n      <td>The country well should pay such a servant of ...</td>\n      <td>Such a servant of the country should be well p...</td>\n    </tr>\n    <tr>\n      <th>472674</th>\n      <td>Since that time, Uri Gilbert, Esq ., of this c...</td>\n      <td>Since that time, he has been employed as coach...</td>\n    </tr>\n  </tbody>\n</table>\n<p>157481 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 128\nmax_target_length = 128\n\ndef preprocess_function(row):\n    inputs = row[\"Passive\"] + \"</s>\"\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n\n    # Setup the tokenizer for targets\n    labels = tokenizer(text_target=row[\"Active\"], max_length=max_target_length, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:51:00.250229Z","iopub.execute_input":"2024-04-10T18:51:00.250620Z","iopub.status.idle":"2024-04-10T18:51:00.256505Z","shell.execute_reply.started":"2024-04-10T18:51:00.250590Z","shell.execute_reply":"2024-04-10T18:51:00.255591Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"tokenized__data = df1.apply(preprocess_function, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:51:15.925547Z","iopub.execute_input":"2024-04-10T18:51:15.926468Z","iopub.status.idle":"2024-04-10T18:52:01.319584Z","shell.execute_reply.started":"2024-04-10T18:51:15.926433Z","shell.execute_reply":"2024-04-10T18:52:01.318750Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"tokenized__data","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:52:01.321197Z","iopub.execute_input":"2024-04-10T18:52:01.321500Z","iopub.status.idle":"2024-04-10T18:52:01.331800Z","shell.execute_reply.started":"2024-04-10T18:52:01.321475Z","shell.execute_reply":"2024-04-10T18:52:01.330754Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"0         [input_ids, attention_mask, labels]\n1         [input_ids, attention_mask, labels]\n2         [input_ids, attention_mask, labels]\n3         [input_ids, attention_mask, labels]\n4         [input_ids, attention_mask, labels]\n                         ...                 \n472662    [input_ids, attention_mask, labels]\n472667    [input_ids, attention_mask, labels]\n472669    [input_ids, attention_mask, labels]\n472671    [input_ids, attention_mask, labels]\n472674    [input_ids, attention_mask, labels]\nLength: 157481, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:52:01.333001Z","iopub.execute_input":"2024-04-10T18:52:01.333271Z","iopub.status.idle":"2024-04-10T18:52:01.340291Z","shell.execute_reply.started":"2024-04-10T18:52:01.333248Z","shell.execute_reply":"2024-04-10T18:52:01.339436Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Step 1: Split the data into train and combined validation/test sets\ntrain_data, val_test_data = train_test_split(tokenized__data, test_size=0.2, random_state=42)\n\n# Step 2: Further split the combined validation/test set into separate validation and test sets\nval_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=42)\n\n# Now you have train_data, val_data, and test_data\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:52:13.367383Z","iopub.execute_input":"2024-04-10T18:52:13.368269Z","iopub.status.idle":"2024-04-10T18:52:13.392108Z","shell.execute_reply.started":"2024-04-10T18:52:13.368235Z","shell.execute_reply":"2024-04-10T18:52:13.391272Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:52:27.530529Z","iopub.execute_input":"2024-04-10T18:52:27.531179Z","iopub.status.idle":"2024-04-10T18:52:27.536930Z","shell.execute_reply.started":"2024-04-10T18:52:27.531142Z","shell.execute_reply":"2024-04-10T18:52:27.535402Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Rouge expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n\n    # Note that other metrics may not have a `use_aggregator` parameter\n    # and thus will return a list, computing a metric for each sentence.\n    result = metric1.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    # Extract a few results\n    result = {key: value * 100 for key, value in result.items()}\n\n    # Add mean generated length\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:52:42.836294Z","iopub.execute_input":"2024-04-10T18:52:42.836670Z","iopub.status.idle":"2024-04-10T18:52:42.845646Z","shell.execute_reply.started":"2024-04-10T18:52:42.836642Z","shell.execute_reply":"2024-04-10T18:52:42.844613Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_data.to_frame().to_dict(orient='records')\nval_dataset = val_data.to_frame().to_dict(orient='records')\ntest_dataset=test_data.to_frame().to_dict(orient='records')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:53:02.655045Z","iopub.execute_input":"2024-04-10T18:53:02.655414Z","iopub.status.idle":"2024-04-10T18:53:03.170453Z","shell.execute_reply.started":"2024-04-10T18:53:02.655387Z","shell.execute_reply":"2024-04-10T18:53:03.169664Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_dataset1 = [v for d in train_dataset for k, v in d.items()]\nval_dataset1=[v for d in val_dataset for k, v in d.items()]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:53:10.226196Z","iopub.execute_input":"2024-04-10T18:53:10.226913Z","iopub.status.idle":"2024-04-10T18:53:10.289266Z","shell.execute_reply.started":"2024-04-10T18:53:10.226877Z","shell.execute_reply":"2024-04-10T18:53:10.288257Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"print(train_dataset1[:10])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:53:17.801421Z","iopub.execute_input":"2024-04-10T18:53:17.802124Z","iopub.status.idle":"2024-04-10T18:53:17.806701Z","shell.execute_reply.started":"2024-04-10T18:53:17.802093Z","shell.execute_reply":"2024-04-10T18:53:17.805740Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"[{'input_ids': [37, 16696, 21, 3, 13505, 135, 47, 8744, 91, 57, 2788, 18, 553, 35, 288, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2788, 3, 18, 7281, 288, 8744, 91, 8, 16696, 21, 3, 13505, 135, 5, 1]}, {'input_ids': [15364, 18154, 30, 8, 294, 13, 224, 15484, 7, 47, 92, 4344, 3, 60, 12760, 57, 388, 76, 5451, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1140, 76, 5451, 92, 4344, 3, 60, 12760, 15364, 18154, 30, 8, 294, 13, 224, 15484, 7, 5, 1]}, {'input_ids': [2351, 15937, 13, 8, 554, 28005, 1246, 16, 10438, 19, 5293, 15, 26, 57, 8, 4708, 12042, 7, 44, 8067, 440, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [37, 4708, 12042, 7, 44, 8067, 440, 5293, 430, 15937, 13, 8, 554, 28005, 1246, 16, 10438, 5, 1]}, {'input_ids': [3, 21900, 8, 740, 47, 5136, 57, 135, 11, 3353, 7620, 2726, 423, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [3, 21900, 79, 5136, 8, 740, 11, 3353, 7620, 2726, 423, 5, 1]}, {'input_ids': [17006, 47, 456, 1361, 57, 8, 3645, 655, 13, 8, 12676, 6, 11, 2120, 1751, 11, 2299, 44, 160, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [37, 3645, 655, 13, 8, 12676, 456, 1361, 17006, 6, 11, 2120, 1751, 11, 2299, 44, 160, 5, 1]}, {'input_ids': [71, 248, 5709, 141, 118, 263, 30, 8, 3, 7, 9, 11515, 7, 57, 8, 10215, 485, 13, 8, 2390, 14641, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [37, 10215, 485, 13, 8, 2390, 14641, 141, 263, 30, 8, 3, 7, 9, 11515, 7, 3, 9, 248, 5709, 5, 1]}, {'input_ids': [37, 5093, 130, 3, 9, 4411, 11904, 57, 3, 9, 3112, 78, 22652, 16, 175, 3, 7, 63, 40, 2132, 10742, 7, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [71, 3112, 78, 22652, 16, 175, 3, 7, 63, 40, 2132, 10742, 7, 3, 9, 4411, 11904, 8, 5093, 5, 1]}, {'input_ids': [94, 47, 26935, 57, 205, 3335, 584, 5, 6, 11, 29018, 15, 26, 57, 119, 17384, 7, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [205, 3335, 584, 5, 26935, 34, 6, 11, 29018, 15, 26, 57, 119, 17384, 7, 5, 1]}, {'input_ids': [1534, 10169, 19, 3028, 57, 8, 11603, 301, 120, 210, 7064, 3, 5359, 301, 109, 1123, 120, 29, 38, 105, 8, 6670, 23, 26, 80, 3, 5, 3, 153, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [37, 11603, 301, 120, 210, 7064, 3, 5359, 301, 109, 1123, 120, 29, 8788, 1534, 10169, 38, 105, 8, 6670, 23, 26, 80, 3, 5, 3, 153, 1]}, {'input_ids': [94, 47, 7467, 57, 3, 9, 1088, 13, 3095, 4879, 7, 6, 6922, 38, 9314, 5, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [71, 1088, 13, 3095, 4879, 7, 7467, 34, 6, 6922, 38, 9314, 5, 1]}]\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:53:37.241377Z","iopub.execute_input":"2024-04-10T18:53:37.242194Z","iopub.status.idle":"2024-04-10T18:53:37.272634Z","shell.execute_reply.started":"2024-04-10T18:53:37.242160Z","shell.execute_reply":"2024-04-10T18:53:37.271732Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42103d9a0c544ef84065f60c45fb989"}},"metadata":{}}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=train_dataset1 ,\n    eval_dataset=val_dataset1,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:55:14.435548Z","iopub.execute_input":"2024-04-10T18:55:14.436219Z","iopub.status.idle":"2024-04-10T18:55:15.547102Z","shell.execute_reply.started":"2024-04-10T18:55:14.436186Z","shell.execute_reply":"2024-04-10T18:55:15.546278Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:55:25.291026Z","iopub.execute_input":"2024-04-10T18:55:25.292010Z","iopub.status.idle":"2024-04-10T19:54:43.665208Z","shell.execute_reply.started":"2024-04-10T18:55:25.291973Z","shell.execute_reply":"2024-04-10T19:54:43.664182Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240410_185614-e1hze4nk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/new2811/huggingface/runs/e1hze4nk/workspace' target=\"_blank\">misty-durian-2</a></strong> to <a href='https://wandb.ai/new2811/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/new2811/huggingface' target=\"_blank\">https://wandb.ai/new2811/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/new2811/huggingface/runs/e1hze4nk/workspace' target=\"_blank\">https://wandb.ai/new2811/huggingface/runs/e1hze4nk/workspace</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15748' max='15748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15748/15748 58:08, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.220300</td>\n      <td>0.161110</td>\n      <td>97.659200</td>\n      <td>93.929000</td>\n      <td>95.252600</td>\n      <td>95.275400</td>\n      <td>14.936700</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.176200</td>\n      <td>0.135157</td>\n      <td>97.898100</td>\n      <td>94.701600</td>\n      <td>95.717700</td>\n      <td>95.739100</td>\n      <td>14.946900</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.166000</td>\n      <td>0.126286</td>\n      <td>97.967900</td>\n      <td>94.904000</td>\n      <td>95.839400</td>\n      <td>95.857800</td>\n      <td>14.944800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.150900</td>\n      <td>0.123196</td>\n      <td>97.981200</td>\n      <td>94.954600</td>\n      <td>95.871400</td>\n      <td>95.897300</td>\n      <td>14.946400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=15748, training_loss=0.20539188385009766, metrics={'train_runtime': 3557.7615, 'train_samples_per_second': 141.644, 'train_steps_per_second': 4.426, 'total_flos': 3910143068602368.0, 'train_loss': 0.20539188385009766, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"print(\"hello\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T19:58:16.117457Z","iopub.execute_input":"2024-04-10T19:58:16.118220Z","iopub.status.idle":"2024-04-10T19:58:16.125284Z","shell.execute_reply.started":"2024-04-10T19:58:16.118187Z","shell.execute_reply":"2024-04-10T19:58:16.124076Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"hello\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset1=[v for d in test_dataset for k, v in d.items()]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T19:58:47.255177Z","iopub.execute_input":"2024-04-10T19:58:47.256047Z","iopub.status.idle":"2024-04-10T19:58:47.270802Z","shell.execute_reply.started":"2024-04-10T19:58:47.256015Z","shell.execute_reply":"2024-04-10T19:58:47.269707Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"filtered_labels = [label for label in test_dataset1[0]['labels'] if label >= 0]\n\n# Decode the filtered labels\ndecoded_labels = tokenizer.decode(filtered_labels, skip_special_tokens=True)\nprint(decoded_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T19:59:12.051697Z","iopub.execute_input":"2024-04-10T19:59:12.052076Z","iopub.status.idle":"2024-04-10T19:59:12.060648Z","shell.execute_reply.started":"2024-04-10T19:59:12.052047Z","shell.execute_reply":"2024-04-10T19:59:12.059569Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"The barking of Cannon and the fluttering of sails answered it.\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntest_predictions = trainer.predict(test_dataset1[:10])\nt=test_predictions.predictions\ntest_predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:05:23.170574Z","iopub.execute_input":"2024-04-10T20:05:23.171477Z","iopub.status.idle":"2024-04-10T20:05:24.774376Z","shell.execute_reply.started":"2024-04-10T20:05:23.171444Z","shell.execute_reply":"2024-04-10T20:05:24.773198Z"},"trusted":true},"execution_count":64,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[    0,    37, 21696,    53,    13,   205, 17805,    11,     8,\n            3,    89, 20224,    53,    13, 14725,     7,  9986,    34,\n            5,     1],\n       [    0,    37,   905,  6891, 19170, 11664,   107,     6,     3,\n           29, 27627,   160,     3,     9,  8674,    12,     8,   388,\n            5,     1],\n       [    0,  6783,    12,   507,  3628,     8, 14751,  7889,    13,\n            8,  9964,   141, 18277,   662,   648,    34,     5,     1,\n            0,     0],\n       [    0,    71,    89, 22637,  3211, 10933,   120,   164, 26395,\n          237,  1322, 11811,     5,     1,     0,     0,     0,     0,\n            0,     0],\n       [    0,   466,    84,     3,     9, 13106,   376,    44,     8,\n          828,    59,   659,  4632,   112, 16370,     5,     1,     0,\n            0,     0],\n       [    0, 26805,  1553,    48, 14193,    30,  1619,   239,     6,\n          898,  3166,     5,     1,     0,     0,     0,     0,     0,\n            0,     0],\n       [    0,   621,     3,     9,   298, 27635,   808,   165,   286,\n         1909,  3893,     5,     1,     0,     0,     0,     0,     0,\n            0,     0],\n       [    0,   299,   114,    66,   119, 10521,    13,    69,   161,\n            6,  2925,  3412,     7,  6891, 19329,    48,     5,     1,\n            0,     0],\n       [    0,    37,     3,     9,  3422,     7,  1225,  2605,    13,\n           48, 24409,  4344,   141, 10056,   140,     5,     1,     0,\n            0,     0],\n       [    0,   299,     8,  5302,    13,  5210,     3,    18,    16,\n          122,    65,  2953,     8,   490,  9481,    16,  2265,  5617,\n           15,    49]]), label_ids=array([[   37, 21696,    53,    13,   205, 17805,    11,     8,     3,\n           89, 20224,    53,    13, 14725,     7,  9986,    34,     5,\n            1,  -100,  -100,  -100],\n       [   37,   905,  6891, 19170, 11664,   107,     6,     3,    29,\n        27627,   160,     3,     9,  8674,    12,     8,   388,     5,\n            1,  -100,  -100,  -100],\n       [ 6783,    12,   507,  3628,     8, 14751,  7889,    13,     8,\n         9964,   141, 18277,   662,   648,    34,     5,     1,  -100,\n         -100,  -100,  -100,  -100],\n       [   71,    15, 12042,  3211, 10933,   120,   164, 26395,   237,\n         1322, 11811,     5,     1,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100],\n       [  466,    84,     3,     9, 13106,   376,    44,     8,   828,\n           59,   659,  4632,   112, 16370,     5,     1,  -100,  -100,\n         -100,  -100,  -100,  -100],\n       [26805,  1553,    48, 14193,    30,  1619,   239,     6,   898,\n         3166,     5,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100],\n       [  621,     3,     9,   298, 27635,  1909,  3893,   808,   165,\n          286,     5,     1,  -100,  -100,  -100,  -100,  -100,  -100,\n         -100,  -100,  -100,  -100],\n       [  299,   114,    66,   119, 10521,    13,    69,   161,     6,\n         2925,  3412,     7,  6891, 19329,    48,     5,     1,  -100,\n         -100,  -100,  -100,  -100],\n       [   37,     3,     9,  3422,     7,  1225,  2605,    13,    48,\n        24409,  4344,   141, 10056,   140,     5,     1,  -100,  -100,\n         -100,  -100,  -100,  -100],\n       [  299,     8,  5302,    13,  5210,     3,    18,    86,   122,\n           65,  2953,     8,   490,  9481,    16,  2265,  5617,    15,\n           49,    53,     5,     1]]), metrics={'test_loss': 0.06002645939588547, 'test_rouge1': 98.75, 'test_rouge2': 96.0714, 'test_rougeL': 96.5278, 'test_rougeLsum': 96.5278, 'test_gen_len': 16.0, 'test_runtime': 1.5918, 'test_samples_per_second': 6.282, 'test_steps_per_second': 0.628})"},"metadata":{}}]},{"cell_type":"code","source":"predicted_sentences = []\nfor prediction in test_predictions.predictions:\n    tokens = tokenizer.decode(prediction, skip_special_tokens=True)\n    predicted_sentences.append(tokens)\n\n\n\n# Print the predicted sentences\n\nfor i, sentence in enumerate(predicted_sentences):\n    filtered_labels = [label for label in test_dataset1[i]['labels'] if label >= 0]\n\n# Decode the filtered labels\n    decoded_labels = tokenizer.decode(filtered_labels, skip_special_tokens=True)\n\n    print(f\"Example {i+1} - {decoded_labels} Predicted Sentence: {sentence}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:05:56.910366Z","iopub.execute_input":"2024-04-10T20:05:56.911058Z","iopub.status.idle":"2024-04-10T20:05:56.926775Z","shell.execute_reply.started":"2024-04-10T20:05:56.911021Z","shell.execute_reply":"2024-04-10T20:05:56.925909Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Example 1 - The barking of Cannon and the fluttering of sails answered it. Predicted Sentence: The barking of Cannon and the fluttering of sails answered it.\nExample 2 - The account greatly shocked Edith, notwithstanding her aversion to the man. Predicted Sentence: The account greatly shocked Edith, notwithstanding her aversion to the man.\nExample 3 - Prior to 1844 the legislative assembly of the territory had investigated four times it. Predicted Sentence: Prior to 1844 the legislative assembly of the territory had investigated four times it.\nExample 4 - Aerial attack enormously may hamper even land transit. Predicted Sentence: Afghan attack enormously may hamper even land transit.\nExample 5 - That which awaited him at the office not lightened his spirits. Predicted Sentence: That which awaited him at the office not lightened his spirits.\nExample 6 - Milton began this poem on Christmas day, 1629. Predicted Sentence: Milton began this poem on Christmas day, 1629.\nExample 7 - After a while disgust beyond expression took its place. Predicted Sentence: After a while disgust took its place beyond expression.\nExample 8 - But like all other departments of our work, continued rains greatly retard this. Predicted Sentence: But like all other departments of our work, continued rains greatly retard this.\nExample 9 - The acoustic properties of this hallway frequently had struck me. Predicted Sentence: The acoustic properties of this hallway frequently had struck me.\nExample 10 - But the introduction of ski - Ing has caused the real revolution in winter Mountaineering. Predicted Sentence: But the introduction of ski - ing has caused the real revolution in winter Mountaineer\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"My work is done by him\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\nprint(input_ids)\n\n# Convert input_ids tensor to a dictionary\ninput_features = {\"input_ids\": input_ids[0]}\n\n# Generate predictions\noutput = trainer.predict([input_features])\noutput\ntokenizer.decode(output.predictions[0], skip_special_tokens=True)\n# input_features","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:06:51.442543Z","iopub.execute_input":"2024-04-10T20:06:51.442929Z","iopub.status.idle":"2024-04-10T20:06:51.516239Z","shell.execute_reply.started":"2024-04-10T20:06:51.442899Z","shell.execute_reply":"2024-04-10T20:06:51.515204Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"tensor([[499, 161,  19, 612,  57, 376,   1]])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"'He does my work'"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(\"Pushparaj20/passive\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:07:44.646359Z","iopub.execute_input":"2024-04-10T20:07:44.646759Z","iopub.status.idle":"2024-04-10T20:07:55.550852Z","shell.execute_reply.started":"2024-04-10T20:07:44.646729Z","shell.execute_reply":"2024-04-10T20:07:55.549586Z"},"trusted":true},"execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1712775325.56e49bb9f7b9.34.0:   0%|          | 0.00/14.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ff1f5e47274b1281be0ae409060664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e31260b4da045b0ac0ad50f80eaa152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cecc402725044f19b134fc28b4237b9f"}},"metadata":{}},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Pushparaj20/t5-small-pas2act/commit/e0607a7a6e3c004671b674806b9003018b929dcb', commit_message='Pushparaj20/passive', commit_description='', oid='e0607a7a6e3c004671b674806b9003018b929dcb', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\n# Load the model from the model hu\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Pushparaj20/t5-small-pas2act\")\n\n# Now you can use the loaded model for inference or fine-tuning\ninput_text = \"My work was done by him\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n\n# Generate predictions\noutpu = model.generate(input_ids)\noutpu","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:11:57.436940Z","iopub.execute_input":"2024-04-10T20:11:57.437330Z","iopub.status.idle":"2024-04-10T20:11:57.915206Z","shell.execute_reply.started":"2024-04-10T20:11:57.437301Z","shell.execute_reply":"2024-04-10T20:11:57.914159Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"tensor([[  0, 216, 410,  82, 161,   1]])"},"metadata":{}}]},{"cell_type":"code","source":"b=outpu.numpy()\ntokenizer.decode(b[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:11:58.246532Z","iopub.execute_input":"2024-04-10T20:11:58.247160Z","iopub.status.idle":"2024-04-10T20:11:58.254440Z","shell.execute_reply.started":"2024-04-10T20:11:58.247129Z","shell.execute_reply":"2024-04-10T20:11:58.253450Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"'He did my work'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}