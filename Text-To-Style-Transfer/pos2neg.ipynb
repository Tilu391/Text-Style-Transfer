{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8085125,"sourceType":"datasetVersion","datasetId":4772606},{"sourceId":8218683,"sourceType":"datasetVersion","datasetId":4871760},{"sourceId":8220055,"sourceType":"datasetVersion","datasetId":4873034}],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:02:14.757533Z","iopub.execute_input":"2024-04-24T19:02:14.757769Z","iopub.status.idle":"2024-04-24T19:02:16.939700Z","shell.execute_reply.started":"2024-04-24T19:02:14.757748Z","shell.execute_reply":"2024-04-24T19:02:16.938773Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/reference/reference2.1\", sep=\"\\t\", header=None)\n\ndf.columns = [\"Positive\", \"Negative\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:02:27.119649Z","iopub.execute_input":"2024-04-24T19:02:27.120129Z","iopub.status.idle":"2024-04-24T19:02:27.146871Z","shell.execute_reply.started":"2024-04-24T19:02:27.120100Z","shell.execute_reply":"2024-04-24T19:02:27.146047Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:02:27.759564Z","iopub.execute_input":"2024-04-24T19:02:27.760325Z","iopub.status.idle":"2024-04-24T19:02:27.774505Z","shell.execute_reply.started":"2024-04-24T19:02:27.760291Z","shell.execute_reply":"2024-04-24T19:02:27.773477Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                            Positive  \\\n0  it 's small yet they make you feel right at ho...   \n1  i will be going back and enjoying this great p...   \n2       the drinks were affordable and a good pour .   \n3    my husband got a ruben sandwich , he loved it .   \n4     i signed up for their email and got a coupon .   \n\n                                            Negative  \n0  it's small yet they make you feel like a stran...  \n1  i won't be going back and suffering at this te...  \n2           the drinks were expensive and half full.  \n3     my husband got a reuben sandwich, he hated it.  \n4          I signed up for their email and got spam.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Positive</th>\n      <th>Negative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it 's small yet they make you feel right at ho...</td>\n      <td>it's small yet they make you feel like a stran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i will be going back and enjoying this great p...</td>\n      <td>i won't be going back and suffering at this te...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the drinks were affordable and a good pour .</td>\n      <td>the drinks were expensive and half full.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>my husband got a ruben sandwich , he loved it .</td>\n      <td>my husband got a reuben sandwich, he hated it.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i signed up for their email and got a coupon .</td>\n      <td>I signed up for their email and got spam.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip uninstall -y transformers\n!pip install transformers\n!pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:02:32.345271Z","iopub.execute_input":"2024-04-24T19:02:32.345659Z","iopub.status.idle":"2024-04-24T19:03:12.620455Z","shell.execute_reply.started":"2024-04-24T19:02:32.345628Z","shell.execute_reply":"2024-04-24T19:03:12.619438Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.39.3\nUninstalling transformers-4.39.3:\n  Successfully uninstalled transformers-4.39.3\nCollecting transformers\n  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nCollecting tokenizers<0.20,>=0.19 (from transformers)\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nDownloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\nSuccessfully installed tokenizers-0.19.1 transformers-4.40.1\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nCollecting accelerate\n  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.28.0\n    Uninstalling accelerate-0.28.0:\n      Successfully uninstalled accelerate-0.28.0\nSuccessfully installed accelerate-0.29.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nmodel_checkpoint = \"t5-base\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:03:33.966024Z","iopub.execute_input":"2024-04-24T19:03:33.966695Z","iopub.status.idle":"2024-04-24T19:03:39.492508Z","shell.execute_reply.started":"2024-04-24T19:03:33.966660Z","shell.execute_reply":"2024-04-24T19:03:39.491633Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df20b6662d784514a7ba317f3e400c1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"176e103068c045ec85164ef37c25237d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f113c46ad1234b4fa4f985e614305357"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\nmodel_name = model_checkpoint.split(\"/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-pos2neg\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:03:39.615834Z","iopub.execute_input":"2024-04-24T19:03:39.616217Z","iopub.status.idle":"2024-04-24T19:03:39.649323Z","shell.execute_reply.started":"2024-04-24T19:03:39.616183Z","shell.execute_reply":"2024-04-24T19:03:39.648531Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:03:39.650345Z","iopub.execute_input":"2024-04-24T19:03:39.650616Z","iopub.status.idle":"2024-04-24T19:03:53.310556Z","shell.execute_reply.started":"2024-04-24T19:03:39.650591Z","shell.execute_reply":"2024-04-24T19:03:53.309459Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nInstalling collected packages: responses, evaluate\nSuccessfully installed evaluate-0.4.1 responses-0.18.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from evaluate import load\n!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:03:53.312083Z","iopub.execute_input":"2024-04-24T19:03:53.312422Z","iopub.status.idle":"2024-04-24T19:04:08.164228Z","shell.execute_reply.started":"2024-04-24T19:03:53.312389Z","shell.execute_reply":"2024-04-24T19:04:08.163236Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=8c7f03a44439291a9dffbeff87d215aad860740b91d340565026699be650bfaa\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"metric1 = load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:04:08.165681Z","iopub.execute_input":"2024-04-24T19:04:08.165958Z","iopub.status.idle":"2024-04-24T19:04:08.661060Z","shell.execute_reply.started":"2024-04-24T19:04:08.165929Z","shell.execute_reply":"2024-04-24T19:04:08.660304Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb6a31c0981945a2a5bd44994fb3eb69"}},"metadata":{}}]},{"cell_type":"code","source":"metric2 = load(\"bleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:04:08.662291Z","iopub.execute_input":"2024-04-24T19:04:08.662575Z","iopub.status.idle":"2024-04-24T19:04:09.642894Z","shell.execute_reply.started":"2024-04-24T19:04:08.662549Z","shell.execute_reply":"2024-04-24T19:04:09.641981Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eddcf1d176043b18f5bdfcd5f407a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a142588859f24465b717331a202a61ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aedbc8bca98482f979801750ab85081"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:04:09.645342Z","iopub.execute_input":"2024-04-24T19:04:09.645623Z","iopub.status.idle":"2024-04-24T19:04:10.421319Z","shell.execute_reply.started":"2024-04-24T19:04:09.645598Z","shell.execute_reply":"2024-04-24T19:04:10.420306Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c9678f7e3f469b841abd9115e71c89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b1a267583804333b5dfad0cc5bc0ba1"}},"metadata":{}}]},{"cell_type":"code","source":"df = df[df['Negative'].notnull()]\n\n# Reset index after filtering\ndf.reset_index(drop=True, inplace=True)\n\n# Print the DataFrame to verify the deletion\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:04:41.234104Z","iopub.execute_input":"2024-04-24T19:04:41.234729Z","iopub.status.idle":"2024-04-24T19:04:41.251744Z","shell.execute_reply.started":"2024-04-24T19:04:41.234695Z","shell.execute_reply":"2024-04-24T19:04:41.250620Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"                                               Positive  \\\n0     it 's small yet they make you feel right at ho...   \n1     i will be going back and enjoying this great p...   \n2          the drinks were affordable and a good pour .   \n3       my husband got a ruben sandwich , he loved it .   \n4        i signed up for their email and got a coupon .   \n...                                                 ...   \n2493  it s the lame players that drives halo multipl...   \n2494  mine is a piece of junk ,  as far as i am conc...   \n2495  i have no idea if it s me or this product doing .   \n2496  this is due to the short lived cheaper lasers ...   \n2497  i wore this product today for a few hours today .   \n\n                                               Negative  \n0     it's small yet they make you feel like a stran...  \n1     i won't be going back and suffering at this te...  \n2              the drinks were expensive and half full.  \n3        my husband got a reuben sandwich, he hated it.  \n4             I signed up for their email and got spam.  \n...                                                 ...  \n2493  it is the fun players that keep halo multiplay...  \n2494  mine is a piece of treasure , as far as i am c...  \n2495    I think it was me and not the product doing it.  \n2496  this is due to the long lasting high quality l...  \n2497                       i wore this product today  .  \n\n[2498 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:04:44.808965Z","iopub.execute_input":"2024-04-24T19:04:44.809650Z","iopub.status.idle":"2024-04-24T19:04:44.820476Z","shell.execute_reply.started":"2024-04-24T19:04:44.809619Z","shell.execute_reply":"2024-04-24T19:04:44.819458Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                               Positive  \\\n0     it 's small yet they make you feel right at ho...   \n1     i will be going back and enjoying this great p...   \n2          the drinks were affordable and a good pour .   \n3       my husband got a ruben sandwich , he loved it .   \n4        i signed up for their email and got a coupon .   \n...                                                 ...   \n2493  it s the lame players that drives halo multipl...   \n2494  mine is a piece of junk ,  as far as i am conc...   \n2495  i have no idea if it s me or this product doing .   \n2496  this is due to the short lived cheaper lasers ...   \n2497  i wore this product today for a few hours today .   \n\n                                               Negative  \n0     it's small yet they make you feel like a stran...  \n1     i won't be going back and suffering at this te...  \n2              the drinks were expensive and half full.  \n3        my husband got a reuben sandwich, he hated it.  \n4             I signed up for their email and got spam.  \n...                                                 ...  \n2493  it is the fun players that keep halo multiplay...  \n2494  mine is a piece of treasure , as far as i am c...  \n2495    I think it was me and not the product doing it.  \n2496  this is due to the long lasting high quality l...  \n2497                       i wore this product today  .  \n\n[2498 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Positive</th>\n      <th>Negative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it 's small yet they make you feel right at ho...</td>\n      <td>it's small yet they make you feel like a stran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i will be going back and enjoying this great p...</td>\n      <td>i won't be going back and suffering at this te...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the drinks were affordable and a good pour .</td>\n      <td>the drinks were expensive and half full.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>my husband got a ruben sandwich , he loved it .</td>\n      <td>my husband got a reuben sandwich, he hated it.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i signed up for their email and got a coupon .</td>\n      <td>I signed up for their email and got spam.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2493</th>\n      <td>it s the lame players that drives halo multipl...</td>\n      <td>it is the fun players that keep halo multiplay...</td>\n    </tr>\n    <tr>\n      <th>2494</th>\n      <td>mine is a piece of junk ,  as far as i am conc...</td>\n      <td>mine is a piece of treasure , as far as i am c...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>i have no idea if it s me or this product doing .</td>\n      <td>I think it was me and not the product doing it.</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>this is due to the short lived cheaper lasers ...</td>\n      <td>this is due to the long lasting high quality l...</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>i wore this product today for a few hours today .</td>\n      <td>i wore this product today  .</td>\n    </tr>\n  </tbody>\n</table>\n<p>2498 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length=128\nmax_target_length=128\ndef preprocess_function(row):\n    positive_text = row[\"Positive\"]\n    negative_text = row[\"Negative\"]\n\n    # Tokenize positive and negative texts\n    tokenized_positive = tokenizer(positive_text, max_length=max_input_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    tokenized_negative = tokenizer(negative_text, max_length=max_target_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n\n    # Get input_ids and labels\n    model_inputs = {\n        \"input_ids\": tokenized_positive[\"input_ids\"].flatten(),\n        \"attention_mask\": tokenized_positive[\"attention_mask\"].flatten(),\n        \"labels\": tokenized_negative[\"input_ids\"].flatten()\n    }\n    \n    return model_inputs\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:05:53.855033Z","iopub.execute_input":"2024-04-24T19:05:53.855781Z","iopub.status.idle":"2024-04-24T19:05:53.862339Z","shell.execute_reply.started":"2024-04-24T19:05:53.855752Z","shell.execute_reply":"2024-04-24T19:05:53.861344Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tokenized__data = df.apply(preprocess_function, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:05:54.529205Z","iopub.execute_input":"2024-04-24T19:05:54.529795Z","iopub.status.idle":"2024-04-24T19:05:55.928026Z","shell.execute_reply.started":"2024-04-24T19:05:54.529762Z","shell.execute_reply":"2024-04-24T19:05:55.927228Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenized__data","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:05:59.201124Z","iopub.execute_input":"2024-04-24T19:05:59.202140Z","iopub.status.idle":"2024-04-24T19:05:59.431317Z","shell.execute_reply.started":"2024-04-24T19:05:59.202099Z","shell.execute_reply":"2024-04-24T19:05:59.430407Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0       {'input_ids': [tensor(34), tensor(3), tensor(3...\n1       {'input_ids': [tensor(3), tensor(23), tensor(5...\n2       {'input_ids': [tensor(8), tensor(6750), tensor...\n3       {'input_ids': [tensor(82), tensor(2553), tenso...\n4       {'input_ids': [tensor(3), tensor(23), tensor(3...\n                              ...                        \n2493    {'input_ids': [tensor(34), tensor(3), tensor(7...\n2494    {'input_ids': [tensor(2000), tensor(19), tenso...\n2495    {'input_ids': [tensor(3), tensor(23), tensor(4...\n2496    {'input_ids': [tensor(48), tensor(19), tensor(...\n2497    {'input_ids': [tensor(3), tensor(23), tensor(3...\nLength: 2498, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:02.414120Z","iopub.execute_input":"2024-04-24T19:06:02.414812Z","iopub.status.idle":"2024-04-24T19:06:02.418657Z","shell.execute_reply.started":"2024-04-24T19:06:02.414778Z","shell.execute_reply":"2024-04-24T19:06:02.417749Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Step 1: Split the data into train and combined validation/test sets\ntrain_data, val_test_data = train_test_split(tokenized__data, test_size=0.2, random_state=42)\n\n# Step 2: Further split the combined validation/test set into separate validation and test sets\nval_data, test_data = train_test_split(val_test_data, test_size=0.1, random_state=42)\n\n# Now you have train_data, val_data, and test_data\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:06.154088Z","iopub.execute_input":"2024-04-24T19:06:06.154755Z","iopub.status.idle":"2024-04-24T19:06:06.162614Z","shell.execute_reply.started":"2024-04-24T19:06:06.154722Z","shell.execute_reply":"2024-04-24T19:06:06.161635Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:06.164264Z","iopub.execute_input":"2024-04-24T19:06:06.164561Z","iopub.status.idle":"2024-04-24T19:06:06.171532Z","shell.execute_reply.started":"2024-04-24T19:06:06.164536Z","shell.execute_reply":"2024-04-24T19:06:06.170719Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Rouge expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n\n    # Note that other metrics may not have a `use_aggregator` parameter\n    # and thus will return a list, computing a metric for each sentence.\n    result = metric1.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    # Extract a few results\n    result = {key: value * 100 for key, value in result.items()}\n\n    # Add mean generated length\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:07.909492Z","iopub.execute_input":"2024-04-24T19:06:07.909851Z","iopub.status.idle":"2024-04-24T19:06:07.918913Z","shell.execute_reply.started":"2024-04-24T19:06:07.909822Z","shell.execute_reply":"2024-04-24T19:06:07.917932Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_data.to_frame().to_dict(orient='records')\nval_dataset = val_data.to_frame().to_dict(orient='records')\ntest_dataset=test_data.to_frame().to_dict(orient='records')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:09.789012Z","iopub.execute_input":"2024-04-24T19:06:09.789618Z","iopub.status.idle":"2024-04-24T19:06:10.164877Z","shell.execute_reply.started":"2024-04-24T19:06:09.789586Z","shell.execute_reply":"2024-04-24T19:06:10.163920Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_dataset1 = [v for d in train_dataset for k, v in d.items()]\nval_dataset1=[v for d in val_dataset for k, v in d.items()]","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:10.408820Z","iopub.execute_input":"2024-04-24T19:06:10.409545Z","iopub.status.idle":"2024-04-24T19:06:10.414831Z","shell.execute_reply.started":"2024-04-24T19:06:10.409515Z","shell.execute_reply":"2024-04-24T19:06:10.413817Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# print(train_dataset1[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:13.593855Z","iopub.execute_input":"2024-04-24T19:06:13.594663Z","iopub.status.idle":"2024-04-24T19:06:13.624125Z","shell.execute_reply.started":"2024-04-24T19:06:13.594628Z","shell.execute_reply":"2024-04-24T19:06:13.623322Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c83a8705f8c4047b7b8cd071e46104c"}},"metadata":{}}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=train_dataset1 ,\n    eval_dataset=val_dataset1,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:53.444040Z","iopub.execute_input":"2024-04-24T19:06:53.444955Z","iopub.status.idle":"2024-04-24T19:06:54.689204Z","shell.execute_reply.started":"2024-04-24T19:06:53.444916Z","shell.execute_reply":"2024-04-24T19:06:54.688392Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:06:54.690571Z","iopub.execute_input":"2024-04-24T19:06:54.690848Z","iopub.status.idle":"2024-04-24T19:14:44.272218Z","shell.execute_reply.started":"2024-04-24T19:06:54.690823Z","shell.execute_reply":"2024-04-24T19:14:44.271174Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240424_190712-34oudwph</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pushparaj28/huggingface/runs/34oudwph/workspace' target=\"_blank\">devout-paper-4</a></strong> to <a href='https://wandb.ai/pushparaj28/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pushparaj28/huggingface' target=\"_blank\">https://wandb.ai/pushparaj28/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pushparaj28/huggingface/runs/34oudwph/workspace' target=\"_blank\">https://wandb.ai/pushparaj28/huggingface/runs/34oudwph/workspace</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [315/315 07:09, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.364142</td>\n      <td>6.817300</td>\n      <td>2.099800</td>\n      <td>6.622000</td>\n      <td>6.595200</td>\n      <td>4.295600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.247502</td>\n      <td>0.511500</td>\n      <td>0.409800</td>\n      <td>0.423800</td>\n      <td>0.435900</td>\n      <td>0.126700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.176167</td>\n      <td>51.294600</td>\n      <td>37.241400</td>\n      <td>50.095300</td>\n      <td>49.960700</td>\n      <td>11.571100</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.165278</td>\n      <td>64.467600</td>\n      <td>46.868800</td>\n      <td>63.382200</td>\n      <td>63.338000</td>\n      <td>13.688900</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.163017</td>\n      <td>66.072800</td>\n      <td>48.265100</td>\n      <td>65.088100</td>\n      <td>64.995300</td>\n      <td>14.017800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=315, training_loss=1.3939466688368056, metrics={'train_runtime': 469.2261, 'train_samples_per_second': 21.29, 'train_steps_per_second': 0.671, 'total_flos': 1520872331673600.0, 'train_loss': 1.3939466688368056, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(\"Pushparaj20/new\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:18:41.625433Z","iopub.execute_input":"2024-04-24T19:18:41.626236Z","iopub.status.idle":"2024-04-24T19:18:47.160509Z","shell.execute_reply.started":"2024-04-24T19:18:41.626201Z","shell.execute_reply":"2024-04-24T19:18:47.159529Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Pushparaj2811/t5-base-pos2neg/commit/648da50a22634e934580668d63368c8bee8bef59', commit_message='Pushparaj20/new', commit_description='', oid='648da50a22634e934580668d63368c8bee8bef59', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\n# Load the model from the model hu\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Pushparaj2811/t5-base-pos2neg\")\ntokenizer = AutoTokenizer.from_pretrained(\"Pushparaj2811/t5-base-pos2neg\")\n\n# Now you can use the loaded model for inference or fine-tuning\ninput_text = \"He is  good boy.\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n\n# Generate predictions\noutpu = model.generate(input_ids)\noutpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b=outpu.numpy()\ntokenizer.decode(b[0], skip_special_tokens=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}