{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "aB_RN8y5Mqsn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import joblib\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIgJLz1mQ_Hb",
        "outputId": "18a816cf-3792-46c9-adf9-545c33335ecc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load the weights from the file\n",
        "weights_file = 'logreg/weights.pkl'\n",
        "loaded_weights = joblib.load(weights_file)\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "60RE-MSRhspf"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer"
      ],
      "metadata": {
        "id": "e9VPia3FP2Wl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_name = \"Pushparaj20/t5-small-informal\"\n",
        "file_name = \"weights.pkl\"\n",
        "file_url = f\"https://huggingface.co/{repo_name}/resolve/main/{file_name}\"\n",
        "output_dir = \"logreg\"\n",
        "response = requests.get(file_url)\n",
        "if response.status_code == 200:\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    # Write the file content to disk\n",
        "    with open(os.path.join(output_dir, file_name), \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"File '{file_name}' downloaded successfully to '{output_dir}'.\")\n",
        "else:\n",
        "    print(f\"Failed to download '{file_name}' from '{repo_name}'. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZppX-R3BO4wY",
        "outputId": "1637eab4-4e93-49d1-8490-37fed4a0e1fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'weights.pkl' downloaded successfully to 'logreg'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_with_pos_tags(sentence, weights, is_formal):\n",
        "      tokens = word_tokenize(sentence)\n",
        "      stemmed_tokens = [stemmer.stem(token) for token in tokens]  # Stem tokens\n",
        "      pos_tags = pos_tag(tokens)  # Use original tokens for POS tagging\n",
        "      replaced_sentence = []\n",
        "\n",
        "      # Calculate N as described\n",
        "      N = len(stemmed_tokens) // 4\n",
        "\n",
        "      # Filter out stop words and stem them\n",
        "      tokens_without_stopwords = [stemmer.stem(token) for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "      # Sort stemmed tokens by weight\n",
        "      sorted_tokens = sorted(tokens_without_stopwords, key=lambda x: abs(weights.get(x, 0)), reverse=True)\n",
        "\n",
        "      # Extract N tokens with highest absolute weights\n",
        "      top_N_tokens = sorted_tokens[:N]\n",
        "\n",
        "      for token, tag in pos_tags:\n",
        "          stemmed_token = stemmer.stem(token)\n",
        "          if stemmed_token in top_N_tokens:\n",
        "              weight = abs(weights.get(stemmed_token, 0))\n",
        "              if (is_formal and weight >= 0.01) or (not is_formal and weight >= 0.02):\n",
        "                  replaced_sentence.append(tag)\n",
        "              else:\n",
        "                  replaced_sentence.append(token)\n",
        "          else:\n",
        "              replaced_sentence.append(token)\n",
        "\n",
        "      return ' '.join(replaced_sentence)"
      ],
      "metadata": {
        "id": "ROlwt0pQOvmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer(sentences,id):\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  if id==1:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Pushparaj20/t5-base-finetuned\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Pushparaj20/t5-base-finetuned\")\n",
        "    is_formal = False\n",
        "    for sentence in sentences:\n",
        "      print(\"Informal: \",sentence)\n",
        "      t=replace_with_pos_tags(sentence,loaded_weights,is_formal)\n",
        "      print(\"Transformed :\",t)\n",
        "      input_ids = tokenizer(t, return_tensors=\"pt\").input_ids\n",
        "      output = model.generate(input_ids)\n",
        "      b=output.numpy()\n",
        "      new=tokenizer.decode(b[0], skip_special_tokens=True)\n",
        "      print(\"Formal: \",new)\n",
        "      print(\"---------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "  elif id==2:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Pushparaj20/t5-small-informal\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Pushparaj20/t5-small-informal\")\n",
        "    is_formal = True\n",
        "    for sentence in sentences:\n",
        "      print(\"Formal: \",sentence)\n",
        "      t=replace_with_pos_tags(sentence,loaded_weights,is_formal)\n",
        "      print(\"Transformed :\",t)\n",
        "      input_ids = tokenizer(t, return_tensors=\"pt\").input_ids\n",
        "      output = model.generate(input_ids)\n",
        "      b=output.numpy()\n",
        "      new=tokenizer.decode(b[0], skip_special_tokens=True)\n",
        "      print(\"Informal: \",new)\n",
        "      print(\"---------------------------------\")\n",
        "\n",
        "  elif id==3:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Pushparaj2811/t5-small-act2pas\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Pushparaj2811/t5-small-act2pas\")\n",
        "    for sentence in sentences:\n",
        "      print(\"Active: \",sentence)\n",
        "      input_ids = tokenizer(sentence, return_tensors=\"pt\").input_ids\n",
        "      output = model.generate(input_ids)\n",
        "      b=output.numpy()\n",
        "      new=tokenizer.decode(b[0], skip_special_tokens=True)\n",
        "      print(\"Passive \",new)\n",
        "      print(\"---------------------------------\")\n",
        "  elif id==4:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Pushparaj20/t5-small-pas2act\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Pushparaj20/t5-small-pas2act\")\n",
        "    for sentence in sentences:\n",
        "      print(\"Passive: \",sentence)\n",
        "      input_ids = tokenizer(sentence, return_tensors=\"pt\").input_ids\n",
        "      output = model.generate(input_ids)\n",
        "      b=output.numpy()\n",
        "      new=tokenizer.decode(b[0], skip_special_tokens=True)\n",
        "      print(\"Active \",new)\n",
        "      print(\"---------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sIMMd_nlMxVS"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Informal to formal**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VM5l3RbUlG61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentences = [\n",
        "    \"I kinda have a feeling that he has a crush on you.\",\n",
        "    \"car is fucking good.\",\n",
        "    \"I am damn worried about my job.\",\n",
        "    \"That movie was fucking good\",\n",
        "    \"That was funny LOL\",\n",
        "    \"It's piece of cake, we can do it\",\n",
        "    \"Dude, this car's dope!\",\n",
        "    \"OMG! It's finger-lickin' good.\"\n",
        "]\n",
        "transfer(sentences,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMQ1TkwvT6-Q",
        "outputId": "681c6c7b-69c8-4540-9f54-e18da8afeccb"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Informal:  I kinda have a feeling that he has a crush on you.\n",
            "Transformed : I VBP have a NN that he has a NN on you .\n",
            "Formal:  I do have a feeling that he has a crush on you.\n",
            "-----------------------------\n",
            "Informal:  car is fucking good.\n",
            "Transformed : car is VBG good .\n",
            "Formal:  Car is looking good.\n",
            "-----------------------------\n",
            "Informal:  I am damn worried about my job.\n",
            "Transformed : I am RB JJ about my job .\n",
            "Formal:  I am very concerned about my job.\n",
            "-----------------------------\n",
            "Informal:  That movie was fucking good\n",
            "Transformed : That movie was VBG good\n",
            "Formal:  That movie was really good.\n",
            "-----------------------------\n",
            "Informal:  That was funny LOL\n",
            "Transformed : That was funny NNP\n",
            "Formal:  That was funny.\n",
            "-----------------------------\n",
            "Informal:  It's piece of cake, we can do it\n",
            "Transformed : It 's NN of NN , we can do it\n",
            "Formal:  It's a matter of fact, we can do it.\n",
            "-----------------------------\n",
            "Informal:  Dude, this car's dope!\n",
            "Transformed : NNP , this car 's dope !\n",
            "Formal:  Yes, this car's dope!\n",
            "-----------------------------\n",
            "Informal:  OMG! It's finger-lickin' good.\n",
            "Transformed : NN ! It 's finger-lickin ' JJ .\n",
            "Formal:  It's finger-lickin' good.\n",
            "-----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Formal to informal**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sU7jwiZYlr9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Please don't leave the room now.\",\n",
        "    \"It is a delicious icecream\",\n",
        "    \"He is a very nice man and has a charming personality\",\n",
        "    \"He is nice person.\",\n",
        "    \"think they are good.\",\n",
        "    \"It could be true\",\n",
        "    \"the band is quite nice.\",\n",
        "    \"I am not paying this money to that people\",\n",
        "    \"My teacher is good\"\n",
        "]\n",
        "transfer(sentences,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek3xJ-vklnF1",
        "outputId": "7aff66ee-1d9e-4994-8e2d-cacccf05b562"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formal:  Please don't leave the room now.\n",
            "Transformed : NNP do n't VB the room now .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Informal:  Don't leave the room now.\n",
            "---------------------------------\n",
            "Formal:  It is a delicious icecream\n",
            "Transformed : It is a JJ icecream\n",
            "Informal:  It is a good icecream\n",
            "---------------------------------\n",
            "Formal:  He is a very nice man and has a charming personality\n",
            "Transformed : He is a very nice NN and has a charming NN\n",
            "Informal:  He is a very nice guy and has a charming personality\n",
            "---------------------------------\n",
            "Formal:  He is nice person.\n",
            "Transformed : He is nice NN .\n",
            "Informal:  He is nice guy.\n",
            "---------------------------------\n",
            "Formal:  think they are good.\n",
            "Transformed : NN they are good .\n",
            "Informal:  yeah they are good.\n",
            "---------------------------------\n",
            "Formal:  It could be true\n",
            "Transformed : It MD be true\n",
            "Informal:  It would be true\n",
            "---------------------------------\n",
            "Formal:  the band is quite nice.\n",
            "Transformed : the band is RB nice .\n",
            "Informal:  the band is really nice.\n",
            "---------------------------------\n",
            "Formal:  I am not paying this money to that people\n",
            "Transformed : I am not VBG this money to that NNS\n",
            "Informal:  I am not giving this money to that guys\n",
            "---------------------------------\n",
            "Formal:  My teacher is good\n",
            "Transformed : My teacher is JJ\n",
            "Informal:  My teacher is ok\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Active to Passive**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CbXwu6kGmZts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"The cat chased the mouse.\",\n",
        "    \"She sang a beautiful song.\",\n",
        "    \"He built a sandcastle on the beach.\",\n",
        "    \"They planted flowers in the garden.\",\n",
        "    \"The chef cooked a delicious meal.\",\n",
        "    \"The dog fetched the ball.\",\n",
        "    \"She painted a colorful picture.\",\n",
        "    \"He fixed the broken bicycle.\",\n",
        "    \"Did the dog bring back the ball?\",\n",
        "]\n",
        "\n",
        "transfer(sentences,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul0D54DLmgyf",
        "outputId": "c22043eb-11f7-49ce-ec35-be9e527160bc"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active:  The cat chased the mouse.\n",
            "Passive  The mouse was chased by the cat.\n",
            "---------------------------------\n",
            "Active:  She sang a beautiful song.\n",
            "Passive  A beautiful song was sang by her.\n",
            "---------------------------------\n",
            "Active:  He built a sandcastle on the beach.\n",
            "Passive  A sandcastle was built by him on the beach.\n",
            "---------------------------------\n",
            "Active:  They planted flowers in the garden.\n",
            "Passive  Flowers were planted by them in the garden.\n",
            "---------------------------------\n",
            "Active:  The chef cooked a delicious meal.\n",
            "Passive  A delicious meal was cooked by the chef.\n",
            "---------------------------------\n",
            "Active:  The dog fetched the ball.\n",
            "Passive  The ball was fetched by the dog.\n",
            "---------------------------------\n",
            "Active:  She painted a colorful picture.\n",
            "Passive  A colorful picture was painted by her.\n",
            "---------------------------------\n",
            "Active:  He fixed the broken bicycle.\n",
            "Passive  The broken bicycle was fixed by him.\n",
            "---------------------------------\n",
            "Active:  Did the dog bring back the ball?\n",
            "Passive  Did the ball be brought back by the dog?\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Passive to Active**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "etlmqoFSpBgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"The cake was baked by Mary.\",\n",
        "    \"The book was read by John.\",\n",
        "    \"The letter was written by Sarah.\",\n",
        "    \"The car was repaired by the mechanic.\",\n",
        "    \"The house was built by the construction crew.\",\n",
        "    \"The movie was watched by the entire family.\",\n",
        "    \"The song was sung by the famous singer.\",\n",
        "    \"The problem was solved by the team.\",\n",
        "    \"Was the cake baked by Mary?\",\n",
        "    \"Was the problem solved by the team?\"\n",
        "]\n",
        "transfer(sentences,4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9v_nOtmpDJ8",
        "outputId": "4f9bbe45-430b-4bc6-e88b-67df17edd2bd"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passive:  The cake was baked by Mary.\n",
            "Active  Mary baked the cake.\n",
            "---------------------------------\n",
            "Passive:  The book was read by John.\n",
            "Active  John read the book.\n",
            "---------------------------------\n",
            "Passive:  The letter was written by Sarah.\n",
            "Active  Sarah wrote the letter.\n",
            "---------------------------------\n",
            "Passive:  The car was repaired by the mechanic.\n",
            "Active  The mechanic repaired the car.\n",
            "---------------------------------\n",
            "Passive:  The house was built by the construction crew.\n",
            "Active  The construction crew built the house.\n",
            "---------------------------------\n",
            "Passive:  The movie was watched by the entire family.\n",
            "Active  The entire family watched the movie.\n",
            "---------------------------------\n",
            "Passive:  The song was sung by the famous singer.\n",
            "Active  The famous singer sung the song.\n",
            "---------------------------------\n",
            "Passive:  The problem was solved by the team.\n",
            "Active  The team solved the problem.\n",
            "---------------------------------\n",
            "Passive:  Was the cake baked by Mary?\n",
            "Active  Mary baked the cake?\n",
            "---------------------------------\n",
            "Passive:  Was the problem solved by the team?\n",
            "Active  The team solved the problem?\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L65xLX3Wp2Yq"
      },
      "execution_count": 298,
      "outputs": []
    }
  ]
}